{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb6318f9",
   "metadata": {},
   "source": [
    "# Detectar arritmias cardíacas mediante señales de ECG parcialmente etiquetadas\n",
    "### INF395 Introducción a las Redes Neuronales and Deep Learning\n",
    "- Estudiante: Alessandro Bruno Cintolesi Rodríguez\n",
    "- ROL: 202173541-0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbd52dd",
   "metadata": {},
   "source": [
    "## **1. Librerias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf7341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === General / Utilidad ===\n",
    "from datetime import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Optional, Dict\n",
    "\n",
    "# === PyTorch / PyTorch Lightning ===\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LambdaLR, CosineAnnealingLR\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# === Scikit-learn ===\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "\tf1_score, accuracy_score, recall_score, confusion_matrix,\n",
    "\troc_auc_score, classification_report\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1f52b9",
   "metadata": {},
   "source": [
    "## **2. Variables globales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c09c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Definición de las clases del dataset (ECG)\n",
    "# ============================================================\n",
    "CLASSES = {\n",
    "\t0: \"(N) Latido normal\",\n",
    "\t1: \"(S) Latido supraventricular\",\n",
    "\t2: \"(V) Latido ventricular ectópico\",\n",
    "\t3: \"(F) Latido de fusión\",\n",
    "\t4: \"(Q) Latido desconocido\"\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# Hiperparámetros de entrenamiento y configuración global\n",
    "# ============================================================\n",
    "SCHEDULER = \"LambdaLR\" # tipo de programador de tasa de aprendizaje (\"LambdaLR\" o \"CosineAnnealingLR\")\n",
    "\n",
    "LOSS_LP = \"FocalLoss\"  # función de pérdida para LinearProbe (CrossEntropy o FocalLoss)\n",
    "GAMMA_LP = 2.0         # parámetro gamma de Focal Loss (controla el foco en errores difíciles)\n",
    "\n",
    "LOSS_FN = \"FocalLoss\"  # función de pérdida para FineTuning (CrossEntropy o FocalLoss)\n",
    "GAMMA_FN = 2.0         # parámetro gamma de Focal Loss (controla el foco en errores difíciles)\n",
    "\n",
    "SEED = 42              # semilla fija para reproducibilidad\n",
    "SIGNALS = 187          # largo de cada señal ECG (número de muestras por ventana)\n",
    "EMBEDDING_DIM = 256    # tamaño del embedding de salida del encoder (ResNet1D)\n",
    "PROJ_HID = 256         # dimensión oculta del proyector (para TimeCLR)\n",
    "PROJ_OUT = 128         # dimensión de salida del proyector (espacio contrastivo)\n",
    "\n",
    "NUM_WORKERS = 0        # número de procesos paralelos para cargar datos (0 = main thread)\n",
    "BATCH_SSL = 512        # tamaño de batch para entrenamiento auto-supervisado (TimeCLR)\n",
    "BATCH_LP = 256         # tamaño de batch para LinearProbe\n",
    "BATCH_FT = 256         # tamaño de batch para FineTuning\n",
    "\n",
    "EPOCHS_SSL = 100       # número de épocas para auto-supervisado\n",
    "EPOCHS_LP = 25         # número de épocas para LinearProbe\n",
    "EPOCHS_FT = 25         # número de épocas para FineTuning\n",
    "\n",
    "LR_SSL = 1e-3          # learning rate para etapa auto-supervisada\n",
    "LR_LP = 1e-3           # learning rate para LinearProbe\n",
    "LR_FT_HEAD = 5e-4      # learning rate para la cabeza del FineTuning\n",
    "LR_FT_ENC = 3e-5       # learning rate para el encoder del FineTuning\n",
    "\n",
    "WD = 5e-3              # weight decay (regularización L2)\n",
    "TEMP = 0.15            # temperatura usada en la pérdida contrastiva NT-Xent\n",
    "\n",
    "ArrayLike = np.ndarray # alias de tipo (para anotaciones de funciones y datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f3668c",
   "metadata": {},
   "source": [
    "## **3. Setup del Dispositivo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3734d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seteamos la semilla\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "pl.seed_everything(SEED, workers=True)\n",
    "\n",
    "# Seteamos el dispositivo\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(\"Using device:\", DEVICE)\n",
    "if DEVICE.type == \"cuda\":\n",
    "\tprint(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc21d6a",
   "metadata": {},
   "source": [
    "## **4. Funciones Auxiliares**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e43bfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ecg(X, y, aug=False, aug_title=\"\"):\n",
    "\ty_class = CLASSES.get(y, \"Sin clasificar\")\n",
    "\ttitle = f\"ECG Clase: {y_class}\"\n",
    "\tif aug:\n",
    "\t\ttitle = title + f\" | {aug_title}\"\n",
    "\n",
    "\tplt.plot(X)\n",
    "\tplt.title(title)\n",
    "\tplt.xlabel(\"Tiempo (muestras)\")\n",
    "\tplt.ylabel(\"Amplitud\")\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d824df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(X, clusters, n_clusters):\n",
    "\tfor i in range(n_clusters):\n",
    "\t\tcluster_mask = clusters == i\n",
    "\t\tcluster_mean = X[cluster_mask].mean(axis=0)\n",
    "\t\tplt.plot(cluster_mean, label=f\"Cluster {i}\")\n",
    "\n",
    "\tplt.legend()\n",
    "\tplt.title(\"Promedio de señal por cluster\")\n",
    "\tplt.xlabel(\"Muestra\")\n",
    "\tplt.ylabel(\"Amplitud promedio\")\n",
    "\tplt.grid(True)\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eb03a0",
   "metadata": {},
   "source": [
    "## **5. Analisis Exploratorio de Datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccab637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos nuestros datos desde los CSV\n",
    "train_df = pd.read_csv(\"ecg_signals/train_semi_supervised.csv\")\n",
    "test_df = pd.read_csv(\"ecg_signals/test_semi_supervised.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b9c497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos nuestros datos en X (serie de tiempo) / y (label)\n",
    "X_train = train_df.iloc[:, :-1].values\n",
    "y_train = train_df.iloc[:, -1].values\n",
    "\n",
    "X_test = test_df.iloc[:, 1:-1].values\n",
    "y_test = test_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3b2e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos nuestros datos de entrenamiento por etiquetados (labeled) y no etiquetados (unlabeled)\n",
    "y_train_np = np.asarray(y_train)\n",
    "mask_unl = np.isnan(y_train_np.astype(float, copy=False)) if y_train_np.dtype.kind in \"fc\" else np.zeros_like(y_train_np, dtype=bool)\n",
    "mask_unl |= (y_train_np == -1)\n",
    "\n",
    "mask_lab = ~mask_unl\n",
    "\n",
    "X_lab_train = X_train[mask_lab]\n",
    "y_lab_train = y_train_np[mask_lab].astype(int)\n",
    "X_unl_train = X_train[mask_unl]\n",
    "\n",
    "num_classes = int(np.unique(y_lab_train).size)\n",
    "T = X_train.shape[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1503191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficando un ECG\n",
    "plot_ecg(X=X_train[1], y=y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88197911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clusters con K-means\n",
    "train_kmeans = KMeans(n_clusters=5, random_state=SEED)\n",
    "train_clusters = train_kmeans.fit_predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f6a4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(X=X_train, clusters=train_clusters, n_clusters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e3f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Conteo de muestras por clase en el conjunto de entrenamiento\n",
    "# ============================================================\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for c, n in zip(unique, counts):\n",
    "\tif not np.isnan(c):\n",
    "\t\tc = int(c)\n",
    "\tprint(f\"Clase {c}: {n} muestras ({n/len(y_train)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb4c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 5 # número total de clases del problema\n",
    "\n",
    "# ============================================================\n",
    "# 1) Preparación de las etiquetas válidas\n",
    "# ============================================================\n",
    "y_valid = y_train[~np.isnan(y_train)]       # elimina valores NaN (no etiquetados)\n",
    "y_valid = y_valid[y_valid >= 0].astype(int) # elimina etiquetas negativas y las convierte a enteros\n",
    "print(\"Clases en y_valid:\", np.unique(y_valid))\n",
    "\n",
    "class_counts = np.bincount(y_valid, minlength=n_classes)\n",
    "print(\"Cantidad por clase (0..4):\", class_counts)\n",
    "\n",
    "# Pesos base: 1 / sqrt(freq)\n",
    "inv_sqrt = 1.0 / np.sqrt(class_counts + 1e-8)\n",
    "inv_sqrt = inv_sqrt / inv_sqrt.mean()\n",
    "print(\"Pesos 1/sqrt(freq) normalizados:\", inv_sqrt)\n",
    "\n",
    "# Suavizado extra\n",
    "alpha = 0.5\n",
    "class_weights_np = inv_sqrt ** alpha\n",
    "class_weights_np = class_weights_np / class_weights_np.mean()\n",
    "print(\"Pesos por clase suavizados para LOSS (0..4):\", class_weights_np)\n",
    "\n",
    "# Tensor PARA LA LOSS (float32)\n",
    "class_weights_loss = torch.tensor(class_weights_np, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b6e38f",
   "metadata": {},
   "source": [
    "## **6. Modelo basado en TimeCLR**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f7b3f1",
   "metadata": {},
   "source": [
    "### **6.1 Augmentaciones del Modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2423017d",
   "metadata": {},
   "source": [
    "La clase ECGTimeAugment define un conjunto de transformaciones aleatorias para señales ECG (series temporales), usadas como data augmentation durante el entrenamiento. Cada método aplica una alteración leve o moderada para generar variaciones realistas de la señal original:\n",
    "- Jitter: añade ruido gaussiano (simula ruido del sensor).\n",
    "- Scaling: cambia levemente la amplitud (simula diferencias en ganancia).\n",
    "- Time Mask: enmascara un fragmento corto de la señal (similar a cutout o SpecAugment).\n",
    "- Crop: recorta y reescala un segmento temporal (simula distintas duraciones o desplazamientos).\n",
    "- El método __call__ ejecuta estas transformaciones con probabilidades independientes (p_jitter, p_scaling, etc.), devolviendo una versión aumentada de la señal.\n",
    "\n",
    "En resumen: esta clase genera variaciones sintéticas y realistas de señales ECG, mejorando la robustez y generalización del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faafddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase que aplica aumentaciones temporales a señales ECG (para robustecer el modelo)\n",
    "class ECGTimeAugment:\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tseries_len: int = SIGNALS,                               # longitud esperada de la señal\n",
    "\t\tp_jitter: float = 0.7,\t\tjitter_sigma: float = 0.008, # probabilidad y nivel de ruido\n",
    "\t\tp_scaling: float = 0.6,\t\tscaling_sigma: float = 0.05, # probabilidad y nivel de escalado\n",
    "\t\tp_tmask: float = 0.3,\t\ttmask_frac=(0.02, 0.06),     # probabilidad y fracción del tiempo a enmascarar\t\n",
    "\t\tp_crop: float = 0.5,\t\tcrop_frac=(0.8, 0.98),       # probabilidad y tamaño relativo del recorte\n",
    "\t\tuse_perm: bool = False                                   # bandera para futuros usos (permute segments)\n",
    "\t):\n",
    "\t\t# Guarda los parámetros de configuración\n",
    "\t\tself.T = series_len\n",
    "\t\tself.p_jitter = p_jitter; self.jitter_sigma = jitter_sigma\n",
    "\t\tself.p_scaling = p_scaling; self.scaling_sigma = scaling_sigma\n",
    "\t\tself.p_tmask = p_tmask; self.tmask_frac = tmask_frac\n",
    "\t\tself.p_crop = p_crop; self.crop_frac = crop_frac\n",
    "\t\tself.use_perm = use_perm\n",
    "\n",
    "\t# --- 1. Jitter: agrega ruido gaussiano a la señal ---\n",
    "\tdef _jitter(self, x):\n",
    "\t\ty = x + np.random.normal(0.0, self.jitter_sigma, size=x.shape)\n",
    "\t\treturn y.astype(x.dtype, copy=False)\n",
    "\n",
    "\t# --- 2. Scaling: multiplica la señal por un factor aleatorio ---\n",
    "\tdef _scaling(self, x):\n",
    "\t\ty = x * np.random.normal(1.0, self.scaling_sigma)\n",
    "\t\treturn y.astype(x.dtype, copy=False)\n",
    "\n",
    "\t# --- 3. Time Mask: pone a cero una ventana temporal aleatoria ---\n",
    "\tdef _time_mask(self, x):\n",
    "\t\ty = x.astype(np.float32, copy=False).copy()\n",
    "\t\t# ancho de la máscara (en número de puntos)\n",
    "\t\tw = max(1, int(self.T * np.random.uniform(*self.tmask_frac)))\n",
    "\t\t# posición inicial del segmento a enmascarar\n",
    "\t\ts = np.random.randint(0, max(1, self.T - w + 1))\n",
    "\t\ty[s:s+w] = 0.0 # \"borra\" esa parte de la señal\n",
    "\t\treturn y.astype(x.dtype, copy=False)\n",
    "\n",
    "\t# --- 4. Crop: recorta un segmento y lo reescala al largo original ---\n",
    "\tdef _crop(self, x):\n",
    "\t\t# define el ancho del recorte (entre 80% y 98% del total por defecto)\n",
    "\t\tw = max(2, int(self.T * np.random.uniform(*self.crop_frac)))\n",
    "\t\t# elige una posición inicial aleatoria\n",
    "\t\ts = np.random.randint(0, max(1, self.T - w + 1))\n",
    "\t\tseg = x[s:s+w] # segmento recortado\n",
    "\t\t# reinterpolamos el segmento al largo original (T)\n",
    "\t\ti_old = np.linspace(0, 1, num=w)\n",
    "\t\ti_new = np.linspace(0, 1, num=self.T)\n",
    "\t\ty = np.interp(i_new, i_old, seg) # interpolación lineal\n",
    "\t\treturn y.astype(x.dtype, copy=False)\n",
    "\n",
    "\t# --- 5. Lógica principal: aplica las transformaciones con probabilidad ---\n",
    "\tdef __call__(self, x):\n",
    "\t\ty = x\n",
    "\t\t# Cada augment se aplica con su respectiva probabilidad\n",
    "\t\tif np.random.rand() < self.p_crop:\n",
    "\t\t\ty = self._crop(y)\n",
    "\t\tif np.random.rand() < self.p_tmask:\n",
    "\t\t\ty = self._time_mask(y)\n",
    "\t\tif np.random.rand() < self.p_scaling:\n",
    "\t\t\ty = self._scaling(y)\n",
    "\t\tif np.random.rand() < self.p_jitter:\n",
    "\t\t\ty = self._jitter(y)\n",
    "\n",
    "\t\t# Devuelve la señal transformada como un array contiguo en memoria\n",
    "\t\treturn np.ascontiguousarray(y, dtype=np.float32)\n",
    "\n",
    "# Instancia del aumentador, indicando la longitud de las señales ECG\n",
    "ecgtime_augment = ECGTimeAugment(series_len=SIGNALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3aab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ecgtime_augment(X_train[1])\n",
    "plot_ecg(X=aug, y=y_train[1], aug=True, aug_title=\"Augmentación\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd149af",
   "metadata": {},
   "source": [
    "### **6.2 Dataset del Modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480a2e5d",
   "metadata": {},
   "source": [
    "Estas tres clases definen datasets especializados para señales ECG (series temporales), adaptados a distintos escenarios de entrenamiento:\n",
    "1. TimeCLRDataset → se usa para aprendizaje contrastivo no supervisado (como TimeCLR):\n",
    "\t- Cada muestra genera dos vistas aumentadas (a1, a2) de la misma señal aplicando transformaciones aleatorias.\n",
    "\t- Ambas vistas se normalizan (z-score) y se devuelven como tensores (1, T) para el cálculo de pérdidas contrastivas (como nt_xent_loss).\n",
    "2. LabeledECGDataset → se usa para entrenamiento supervisado:\n",
    "\t- Cada señal tiene una etiqueta (y).\n",
    "\t- Con cierta probabilidad (p_aug), se aplica una transformación temporal (augmentación).\n",
    "\t- Luego se normaliza y convierte a tensor, devolviendo (x, y) para clasificación.\n",
    "3. UnlabeledECGDataset → versión simplificada sin etiquetas, usada en evaluación o inferencia:\n",
    "\t- Solo normaliza y convierte las señales a tensores.\n",
    "\n",
    "En resumen: Estas clases estructuran los datos ECG para distintos tipos de aprendizaje —contrastivo, supervisado o sin etiquetas— garantizando normalización consistente, formato correcto y compatibilidad directa con DataLoader de PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa72d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Dataset para entrenamiento contrastivo (TimeCLR)\n",
    "# ============================================================\n",
    "class TimeCLRDataset(Dataset):\n",
    "\tdef __init__(self, X, transform=None, eps=1e-6):\n",
    "\t\t# Asegura que X sea un array float32\n",
    "\t\tX = np.asarray(X, dtype=np.float32)\n",
    "\n",
    "\t\t# Soporta dos formatos: (N, T) o (N, 1, T)\n",
    "\t\tif X.ndim == 2:\n",
    "\t\t\tself.X = X\n",
    "\t\telif X.ndim == 3 and X.shape[1] == 1:\n",
    "\t\t\tself.X = X[:, 0, :] # elimina la dimensión de canal\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(\"X debe ser (N, T) o (N, 1, T)\")\n",
    "\t\t\n",
    "\t\t# Guarda longitud de la serie temporal\n",
    "\t\tself.T = self.X.shape[1]\n",
    "\t\tself.transform = transform # función de augmentación temporal\n",
    "\t\tself.eps = eps # evita divisiones por cero en z-score\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\t# Retorna el número de muestras del dataset\n",
    "\t\treturn self.X.shape[0]\n",
    "\n",
    "\tdef _z(self, x):\n",
    "\t\t# Normaliza por z-score: (x - media) / desviación estándar\n",
    "\t\tm, s = x.mean(), x.std()\n",
    "\t\treturn (x - m) / (s + self.eps)\n",
    "\n",
    "\tdef __getitem__(self, idx: int):\n",
    "\t\t# Obtiene la señal correspondiente\n",
    "\t\tx = self.X[idx]\n",
    "\n",
    "\t\t# Aplica dos transformaciones independientes (vistas augmentadas)\n",
    "\t\ta1 = self.transform(x) if self.transform else x\n",
    "\t\ta2 = self.transform(x) if self.transform else x\n",
    "\n",
    "\t\t# Normaliza ambas vistas\n",
    "\t\ta1 = self._z(a1).astype(np.float32, copy=False)\n",
    "\t\ta2 = self._z(a2).astype(np.float32, copy=False)\n",
    "\n",
    "\t\t# Asegura que sean contiguas en memoria (requerido por torch.from_numpy)\n",
    "\t\ta1 = np.ascontiguousarray(a1)\n",
    "\t\ta2 = np.ascontiguousarray(a2)\n",
    "\n",
    "\t\t# Convierte a tensores y agrega dimensión de canal (1, T)\n",
    "\t\tx1 = torch.from_numpy(a1).unsqueeze(0)\n",
    "\t\tx2 = torch.from_numpy(a2).unsqueeze(0)\n",
    "\n",
    "\t\t# Devuelve el par de vistas aumentadas\n",
    "\t\treturn x1, x2\n",
    "\n",
    "# ============================================================\n",
    "# Dataset etiquetado (para entrenamiento supervisado)\n",
    "# ============================================================\n",
    "class LabeledECGDataset(Dataset):\n",
    "\tdef __init__(self, X, y, eps=1e-6, transform=None, p_aug=0.0):\n",
    "\t\t# Guarda señales y etiquetas como arrays numpy\n",
    "\t\tself.X = np.asarray(X, dtype=np.float32)\n",
    "\t\tself.y = np.asarray(y, dtype=np.int64)\n",
    "\n",
    "\t\tself.eps = eps\n",
    "\t\tself.transform = transform # posible augmentación\n",
    "\t\tself.p_aug = p_aug # probabilidad de aplicarla\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\t# Número de ejemplos en el dataset\n",
    "\t\treturn self.X.shape[0]\n",
    "\n",
    "\tdef _z(self, x):\n",
    "\t\t# Normalización z-score\n",
    "\t\tm, s = x.mean(), x.std()\n",
    "\t\treturn (x - m) / (s + self.eps)\n",
    "\n",
    "\tdef __getitem__(self, i):\n",
    "\t\t# Obtiene la señal i-ésima\n",
    "\t\tx = self.X[i]\n",
    "\n",
    "\t\t# Aplica augmentación con probabilidad p_aug\n",
    "\t\tif self.transform is not None and np.random.rand() < self.p_aug:\n",
    "\t\t\tx = self.transform(x)\n",
    "\n",
    "\t\t# Normaliza y convierte a tensor\n",
    "\t\tx = self._z(x)\n",
    "\t\tx = np.ascontiguousarray(x, dtype=np.float32)\n",
    "\t\tx = torch.from_numpy(x).unsqueeze(0)\n",
    "\n",
    "\t\t# Convierte la etiqueta a tensor\n",
    "\t\ty = torch.tensor(self.y[i])\n",
    "\n",
    "\t\t# Retorna el par (señal, etiqueta)\n",
    "\t\treturn x, y\n",
    "\n",
    "# ============================================================\n",
    "# Dataset no etiquetado (para inferencia o pseudo-labeling)\n",
    "# ============================================================\n",
    "class UnlabeledECGDataset(Dataset):\n",
    "\tdef __init__(self, X, eps=1e-6):\n",
    "\t\t# Guarda solo las señales\n",
    "\t\tself.X = np.asarray(X, dtype=np.float32)\n",
    "\t\tself.eps = eps\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\t# Devuelve el número de señales\n",
    "\t\treturn self.X.shape[0]\n",
    "\n",
    "\tdef _z(self, x):\n",
    "\t\t# Normaliza por z-score\n",
    "\t\tm, s = x.mean(), x.std()\n",
    "\t\treturn (x - m) / (s + self.eps)\n",
    "\n",
    "\tdef __getitem__(self, i):\n",
    "\t\t# Normaliza y convierte la señal i-ésima a tensor\n",
    "\t\tx = self._z(self.X[i])\n",
    "\t\tx = np.ascontiguousarray(x, dtype=np.float32)\n",
    "\t\tx = torch.from_numpy(x).unsqueeze(0)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2821a643",
   "metadata": {},
   "source": [
    "### **6.3 Backbone del Modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03326f33",
   "metadata": {},
   "source": [
    "Este ``ResNet1DBackbone`` es un extractor de características para series temporales basado en bloques residuales (``ResBlocks``) de convoluciones 1D:\n",
    "- Cada ``ResBlock1D`` aplica dos convoluciones 1D con normalización (``BatchNorm``) y activación ``ReLU``, además de una conexión residual que permite sumar la entrada original al resultado (facilita el flujo del gradiente y evita el desvanecimiento).\n",
    "- Si las dimensiones cambian (por stride o número de canales), usa un atajo (shortcut) con una convolución 1×1 para ajustar tamaño.\n",
    "- El ``ResNet1DBackbone`` encadena varios de estos bloques, aumentando el número de canales y la dilatación progresivamente para capturar dependencias a distintas escalas temporales.\n",
    "- Finalmente, usa un ``Adaptive Average Pooling`` para resumir toda la señal en un vector y una capa lineal (fc) para proyectarlo al espacio de embedding (emb_dim), entregando una representación compacta del input.\n",
    "\n",
    "En resumen: es una red residual 1D que transforma una señal temporal en un vector de características robusto y multiescala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4302f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloque residual 1D (usa convoluciones sobre series temporales)\n",
    "class ResBlock1D(nn.Module):\n",
    "\tdef __init__(self, in_ch, out_ch, k=7, stride=1, dilation=1):\n",
    "\t\tsuper().__init__()\n",
    "\t\t# Calcula padding para mantener el tamaño (depende de kernel y dilatación)\n",
    "\t\tp = (k//2) * dilation\n",
    "\n",
    "\t\t# Primera convolución: puede reducir la longitud temporal si stride > 1\n",
    "\t\tself.conv1 = nn.Conv1d(in_ch, out_ch, kernel_size=k, stride=stride, padding=p, dilation=dilation, bias=False)\n",
    "\t\tself.bn1 = nn.BatchNorm1d(out_ch)\n",
    "\n",
    "\t\t# Segunda convolución: mantiene tamaño (stride=1)\n",
    "\t\tself.conv2 = nn.Conv1d(out_ch, out_ch, kernel_size=k, stride=1, padding=p, dilation=dilation, bias=False)\n",
    "\t\tself.bn2 = nn.BatchNorm1d(out_ch)\n",
    "\n",
    "\t\t# Shortcut (conexión residual):\n",
    "\t\t# Si las dimensiones cambian, usa conv1x1 para ajustar canales o stride.\n",
    "\t\t# Si no cambian, deja la identidad.\n",
    "\t\tself.shortcut = nn.Sequential(\n",
    "\t\t\tnn.Conv1d(in_ch, out_ch, kernel_size=1, stride=stride, bias=False),\n",
    "\t\t\tnn.BatchNorm1d(out_ch)\n",
    "\t\t) if (in_ch != out_ch or stride != 1) else nn.Identity()\n",
    "\n",
    "\t\t# Activación\n",
    "\t\tself.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t# Camino principal\n",
    "\t\ty = self.relu(self.bn1(self.conv1(x)))\n",
    "\t\ty = self.bn2(self.conv2(y))\n",
    "\n",
    "\t\t# Suma residual (x + F(x))\n",
    "\t\ty = y + (x if isinstance(self.shortcut, nn.Identity) else self.shortcut(x))\n",
    "\n",
    "\t\t# Activación final\n",
    "\t\treturn self.relu(y)\n",
    "\n",
    "# Red residual completa para extracción de embeddings 1D\n",
    "class ResNet1DBackbone(nn.Module):\n",
    "\tdef __init__(self, in_ch=1, emb_dim=256, widths=(64,128,256,256), dilations=(1,2,4,8)):\n",
    "\t\tsuper().__init__()\n",
    "\t\tlayers = []\n",
    "\t\tch = in_ch # canales de entrada (ej. 1 para señales univariadas)\n",
    "\n",
    "\t\t# Construye múltiples etapas (bloques residuales) con distinta anchura y dilatación\n",
    "\t\tfor w, d in zip(widths, dilations):\n",
    "\t\t\t# Primer bloque de la etapa: puede reducir la resolución temporal (stride=2)\n",
    "\t\t\tlayers += [\n",
    "\t\t\t\tResBlock1D(ch, w, k=7, stride=2, dilation=d),\n",
    "\t\t\t\t# Segundo bloque: mantiene tamaño (stride=1)\n",
    "\t\t\t\tResBlock1D(w, w, k=7, stride=1, dilation=d)\n",
    "\t\t\t]\n",
    "\t\t\tch = w # actualiza número de canales para la siguiente etapa\n",
    "\n",
    "\t\t# Secuencia completa de extracción de características\n",
    "\t\tself.feat = nn.Sequential(\n",
    "\t\t\t*layers,\n",
    "\t\t\tnn.AdaptiveAvgPool1d(1) # colapsa dimensión temporal a 1 (pooling global)\n",
    "\t\t)\n",
    "\n",
    "\t\t# Capa lineal final para obtener embedding de tamaño emb_dim\n",
    "\t\tself.fc = nn.Linear(ch, emb_dim)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t# Extrae características convolucionales\n",
    "\t\th = self.feat(x).squeeze(-1) # salida de tamaño (batch, canales)\n",
    "\n",
    "\t\t# Proyección al espacio de embedding\n",
    "\t\treturn self.fc(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8dad49",
   "metadata": {},
   "source": [
    "### **6.4 ProjectionHead del Modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d487bcd",
   "metadata": {},
   "source": [
    "La clase ``ProjectionHead`` es una cabeza de proyección usada comúnmente en modelos de aprendizaje contrastivo (como SimCLR o TimeCLR):\n",
    "- Toma un vector de características (in_dim) producido por un backbone (por ejemplo, el ``ResNet1DBackbone``).\n",
    "- Lo pasa por una pequeña MLP de dos capas lineales con normalización (``BatchNorm1d``) y activación ``ReLU``.\n",
    "- La primera capa expande o transforma el espacio intermedio (hid_dim), y la segunda lo proyecta al espacio de embedding contrastivo (out_dim), donde se calculan las similitudes entre muestras.\n",
    "\n",
    "En resumen: convierte los embeddings del backbone en representaciones normalizadas y compactas ideales para optimizar una pérdida contrastiva (como InfoNCE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a866fd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cabeza de proyección usada en aprendizaje contrastivo (p. ej. SimCLR, TimeCLR)\n",
    "class ProjectionHead(nn.Module):\n",
    "\tdef __init__(self, in_dim: int, hid_dim: int = 256, out_dim: int = 128):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\t# Definimos una red totalmente conectada (MLP) de dos capas\n",
    "\t\tself.net = nn.Sequential(\n",
    "\t\t\t# Capa lineal inicial: transforma el embedding del backbone a un espacio intermedio\n",
    "\t\t\tnn.Linear(in_dim, hid_dim, bias=False),\n",
    "\n",
    "\t\t\t# Normalización por lotes para estabilizar el entrenamiento\n",
    "\t\t\tnn.BatchNorm1d(hid_dim),\n",
    "\n",
    "\t\t\t# Activación no lineal ReLU\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\n",
    "\t\t\t# Segunda capa lineal: proyecta al espacio de embedding final (para contraste)\n",
    "\t\t\tnn.Linear(hid_dim, out_dim, bias=True)\n",
    "\t\t)\n",
    "\n",
    "\t# Propagación hacia adelante\n",
    "\tdef forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\t\t# Aplica la red definida (MLP) al embedding de entrada\n",
    "\t\treturn self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b783fe57",
   "metadata": {},
   "source": [
    "### **6.5 Clasificador del Modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dff75c",
   "metadata": {},
   "source": [
    "La clase ``ClassifierHead`` es una cabeza de clasificación totalmente conectada que transforma el embedding del backbone en predicciones de clase:\n",
    "- Primero aplica una normalización por capa (``LayerNorm``) para estabilizar las entradas.\n",
    "- Luego pasa por una capa lineal + ``ReLU``, que aprende combinaciones no lineales de las características.\n",
    "- Se añade un ``Dropout`` (p_drop) para reducir el overfitting.\n",
    "- Finalmente, una última capa lineal proyecta al número de clases (n_classes).\n",
    "\n",
    "En resumen: convierte el embedding del modelo base en logits de clasificación, listos para una función de pérdida como ``CrossEntropy`` o ``Focal Loss``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8db1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cabeza de clasificación totalmente conectada (MLP simple)\n",
    "class ClassifierHead(nn.Module):\n",
    "\tdef __init__(self, in_dim=256, hid=256, n_classes=5, p_drop=0.4):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\t# Definimos una pequeña red secuencial\n",
    "\t\tself.net = nn.Sequential(\n",
    "\t\t\t# Normalización por capa: estabiliza las activaciones de entrada\n",
    "\t\t\tnn.LayerNorm(in_dim),\n",
    "\n",
    "\t\t\t# Capa lineal: transforma el embedding de entrada al espacio oculto\n",
    "\t\t\tnn.Linear(in_dim, hid),\n",
    "\n",
    "\t\t\t# Activación ReLU: introduce no linealidad\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\n",
    "\t\t\t# Dropout: apaga aleatoriamente neuronas durante el entrenamiento (reduce overfitting)\n",
    "\t\t\tnn.Dropout(p_drop),\n",
    "\n",
    "\t\t\t# Capa lineal final: proyecta al número de clases (produce los logits)\n",
    "\t\t\tnn.Linear(hid, n_classes),\n",
    "\t\t)\n",
    "\n",
    "\t# Propagación hacia adelante: pasa el embedding por la red definida\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279ad9e3",
   "metadata": {},
   "source": [
    "### **6.6 LossFunction del Modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc027a4",
   "metadata": {},
   "source": [
    "##### **6.6.a NTXentLoss**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244604e4",
   "metadata": {},
   "source": [
    "La función ``nt_xent_loss`` implementa la ``NT-Xent Loss`` (Normalized Temperature-scaled Cross-Entropy Loss) usada en modelos contrastivos como ``SimCLR``:\n",
    "- Entrada: dos lotes de embeddings (z1, z2) que representan diferentes vistas (augmentaciones) de las mismas muestras.\n",
    "- Primero normaliza los vectores para que su similitud se mida solo por el ángulo (coseno).\n",
    "- Luego concatena ambos lotes y calcula la matriz de similitudes coseno escalada por una temperatura (temperature) que controla la dispersión.\n",
    "- Los pares positivos son las posiciones correspondientes entre z1 y z2, y todos los demás pares actúan como negativos.\n",
    "- Finalmente aplica cross-entropy para maximizar la similitud de los positivos y minimizar la de los negativos.\n",
    "\n",
    "En resumen: esta función enseña al modelo a acercar representaciones de vistas del mismo ejemplo y alejar las de distintos ejemplos, formando un espacio de embeddings discriminativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa22eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NT-Xent Loss (Normalized Temperature-scaled Cross Entropy Loss)\n",
    "# Usada en aprendizaje contrastivo (por ejemplo, SimCLR)\n",
    "def nt_xent_loss(z1: torch.Tensor, z2: torch.Tensor, temperature: float = 0.2) -> torch.Tensor:\n",
    "\t# --- 1. Normalización ---\n",
    "\t# Normaliza los embeddings por fila (cada vector con norma 1)\n",
    "\t# Esto hace que la similitud se base solo en el ángulo entre vectores (cosine similarity)\n",
    "\tz1 = F.normalize(z1, dim=1)\n",
    "\tz2 = F.normalize(z2, dim=1)\n",
    "\n",
    "\t# Tamaño del batch\n",
    "\tB = z1.size(0)\n",
    "\n",
    "\t# --- 2. Concatenación ---\n",
    "\t# Combina ambos lotes (2B muestras en total)\n",
    "\tZ = torch.cat([z1, z2], dim=0)\n",
    "\n",
    "\t# --- 3. Precisión ---\n",
    "\t# Si los tensores están en media precisión (fp16 o bf16),\n",
    "\t# se convierten a float32 para evitar errores numéricos en el producto matricial\n",
    "\tif Z.dtype in (torch.float16, torch.bfloat16):\n",
    "\t\tZm = Z.float()\n",
    "\telse:\n",
    "\t\tZm = Z\n",
    "\n",
    "\t# --- 4. Similitud ---\n",
    "\t# Calcula la matriz de similitudes coseno (producto punto) entre todos los pares\n",
    "\t# y la escala por la \"temperatura\", que ajusta la suavidad de las probabilidades\n",
    "\tsim = torch.matmul(Zm, Zm.t()) / temperature # (2B x 2B)\n",
    "\n",
    "\t# --- 5. Máscara de auto-similitud ---\n",
    "\t# Crea una máscara identidad para eliminar la comparación de cada muestra consigo misma\n",
    "\tmask = torch.eye(2 * B, dtype=torch.bool, device=Z.device)\n",
    "\tsim = sim.masked_fill(mask, float('-inf'))\n",
    "\n",
    "\t# --- 6. Targets ---\n",
    "\t# Define los índices de los pares positivos:\n",
    "\t# - la muestra i en z1 debe emparejarse con la muestra i en z2\n",
    "\t# - y viceversa\n",
    "\ttarget = torch.cat([\n",
    "\t\ttorch.arange(B, 2 * B, device=Z.device), # pares z1 → z2\n",
    "\t\ttorch.arange(0, B, device=Z.device) # pares z2 → z1\n",
    "\t], dim=0)\n",
    "\n",
    "\t# --- 7. Pérdida ---\n",
    "\t# Aplica cross-entropy sobre la matriz de similitudes:\n",
    "\t# maximiza la similitud con el par positivo y minimiza con los negativos\n",
    "\tloss = F.cross_entropy(sim, target)\n",
    "\n",
    "\t# Devuelve la pérdida promedio\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f75817",
   "metadata": {},
   "source": [
    "##### **6.6.b FocalLoss**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c209927",
   "metadata": {},
   "source": [
    "La clase ``FocalLoss`` implementa la funcion de pérdida ``Focal Loss``, una variante de la pérdida de entropía cruzada diseñada para manejar datasets con clases desbalanceadas:\n",
    "- Idea principal: penaliza más los ejemplos difíciles y reduce el peso de los fáciles, controlado por el parámetro γ (gamma).\n",
    "- Primero calcula la probabilidad logarítmica con log_softmax y la pérdida base cross-entropy sin reducción.\n",
    "- Luego obtiene la probabilidad pt asociada a la clase verdadera.\n",
    "- El término (1 - pt) ** gamma reduce la contribución de las muestras fáciles (cuando pt es alto).\n",
    "- Finalmente promedia el resultado para devolver una pérdida escalar.\n",
    "\n",
    "En resumen: ``FocalLoss`` enfoca el entrenamiento en los ejemplos difíciles y es muy útil para problemas donde una o más clases están subrepresentadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec01e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementación de la Focal Loss\n",
    "# Se usa para problemas con clases desbalanceadas o donde hay muchas muestras fáciles.\n",
    "class FocalLoss(torch.nn.Module):\n",
    "\tdef __init__(self, gamma=2.0, weight=None):\n",
    "\t\tsuper().__init__()\n",
    "\t\t# gamma controla cuánto se reduce la pérdida de las muestras fáciles\n",
    "\t\t# valores mayores a 0 hacen que el modelo se enfoque más en los casos difíciles\n",
    "\t\tself.gamma = gamma\n",
    "\n",
    "\t\t# weight permite asignar un peso distinto a cada clase (útil si están desbalanceadas)\n",
    "\t\tself.weight = weight\n",
    "\tdef forward(self, logits, target):\n",
    "\t\t# --- 1. Cálculo de probabilidades logarítmicas ---\n",
    "\t\t# Convierte los logits (salidas sin normalizar) en log-probabilidades con softmax\n",
    "\t\tlogp = F.log_softmax(logits, dim=1)\n",
    "\n",
    "\t\t# --- 2. Obtiene las probabilidades estándar ---\n",
    "\t\t# p = e^(logp) → probabilidades normales\n",
    "\t\tp = logp.exp()\n",
    "\n",
    "\t\t# --- 3. Calcula la pérdida de entropía cruzada estándar ---\n",
    "\t\t# nll_loss devuelve la pérdida por muestra (sin promediar)\n",
    "\t\tce = F.nll_loss(logp, target, reduction=\"none\", weight=self.weight)\n",
    "\n",
    "\t\t# --- 4. Obtiene la probabilidad de la clase correcta ---\n",
    "\t\t# Extrae p_t: la probabilidad asignada a la clase verdadera para cada muestra\n",
    "\t\tpt = p.gather(1, target.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "\t\t# --- 5. Aplica el factor focal ---\n",
    "\t\t# (1 - pt)^gamma reduce el peso de las muestras fáciles (cuando pt ≈ 1)\n",
    "\t\t# Multiplica por la pérdida de entropía cruzada\n",
    "\t\tloss = (1 - pt) ** self.gamma * ce\n",
    "\n",
    "\t\t# --- 6. Retorna la pérdida promedio del batch ---\n",
    "\t\treturn loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d947328",
   "metadata": {},
   "source": [
    "### **6.7 Arquitectura del Modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686cd723",
   "metadata": {},
   "source": [
    "La clase ``TimeCLRModel`` define un modelo auto-supervisado basado en ``PyTorch Lightning`` para aprender representaciones de señales temporales (como ECG) usando el enfoque contrastivo ``TimeCLR``.\n",
    "- Encoder: usa un ``ResNet1DBackbone`` para extraer embeddings de las señales.\n",
    "- Projector: aplica una MLP (``ProjectionHead``) que transforma los embeddings al espacio donde se calcula la pérdida contrastiva.\n",
    "- training_step: recibe dos vistas aumentadas de la misma señal (x1, x2), obtiene sus proyecciones (z1, z2) y calcula la pérdida ``NT-Xent``, que acerca los pares positivos y aleja los negativos.\n",
    "- configure_optimizers: configura el optimizador ``AdamW`` y un programador de tasa de aprendizaje (warmup + cosine decay o CosineAnnealingLR).\n",
    "- encode: método auxiliar para obtener embeddings normalizados del encoder (sin pasar por la cabeza de proyección).\n",
    "\n",
    "En resumen: ``TimeCLRModel`` entrena una red 1D tipo ResNet a aprender representaciones invariantes a las aumentaciones temporales, que luego pueden reutilizarse en tareas supervisadas como clasificación ECG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088f256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Modelo auto-supervisado basado en TimeCLR\n",
    "# Aprende representaciones contrastivas de señales temporales (ej: ECG)\n",
    "# ============================================================\n",
    "class TimeCLRModel(pl.LightningModule):\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\temb_dim: int = EMBEDDING_DIM, # dimensión del embedding del encoder\n",
    "\t\tproj_hid: int = PROJ_HID,     # tamaño oculto del proyector\n",
    "\t\tproj_out: int = PROJ_OUT,     # dimensión del espacio contrastivo\n",
    "\t\ttemperature: float = TEMP,    # parámetro de temperatura para NT-Xent\n",
    "\t\tlr: float = LR_SSL,           # tasa de aprendizaje\n",
    "\t\tweight_decay: float = WD      # regularización L2\n",
    "\t):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.save_hyperparameters() # guarda los hiperparámetros en el checkpoint\n",
    "\n",
    "\t\t# Encoder convolucional 1D (ej. ResNet1DBackbone)\n",
    "\t\tself.encoder = ResNet1DBackbone(in_ch=1, emb_dim=emb_dim)\n",
    "\n",
    "\t\t# Cabeza de proyección (MLP) que lleva los embeddings al espacio contrastivo\n",
    "\t\tself.projector = ProjectionHead(emb_dim, proj_hid, proj_out)\n",
    "\t\t\n",
    "\t\t# Parámetros del entrenamiento contrastivo\n",
    "\t\tself.temperature = temperature\n",
    "\t\tself.lr = lr\n",
    "\t\tself.weight_decay = weight_decay\n",
    "\n",
    "\t# ------------------------------------------------------------\n",
    "\t# Forward: pasa por el encoder y luego por la cabeza de proyección\n",
    "\t# ------------------------------------------------------------\n",
    "\tdef forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\t\th = self.encoder(x) # embedding del backbone\n",
    "\t\tz = self.projector(h) # proyección al espacio contrastivo\n",
    "\t\treturn z\n",
    "\n",
    "\t# ------------------------------------------------------------\n",
    "\t# Paso de entrenamiento (batch: contiene 2 vistas aumentadas)\n",
    "\t# ------------------------------------------------------------\n",
    "\tdef training_step(self, batch, batch_idx):\n",
    "\t\tx1, x2 = batch # dos vistas del mismo ejemplo\n",
    "\t\tz1 = self(x1) # pasa la primera vista\n",
    "\t\tz2 = self(x2) # pasa la segunda vista\n",
    "\n",
    "\t\t# Calcula la pérdida contrastiva (NT-Xent)\n",
    "\t\tloss = nt_xent_loss(z1, z2, self.temperature)\n",
    "\n",
    "\t\t# Registra la pérdida en barra de progreso y logs\n",
    "\t\tself.log(\"train_loss\", loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "\t\treturn loss\n",
    "\n",
    "\t# ------------------------------------------------------------\n",
    "\t# Configura el optimizador y el scheduler del LR\n",
    "\t# ------------------------------------------------------------\n",
    "\tdef configure_optimizers(self):\n",
    "\t\t# Optimizador AdamW (Adam con weight decay separado)\n",
    "\t\topt = AdamW(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "\n",
    "\t\t# Calcula cantidad total de pasos por época\n",
    "\t\tif self.trainer.datamodule:\n",
    "\t\t\tsteps_per_epoch = len(self.trainer.datamodule.train_dataloader())\n",
    "\t\telse:\n",
    "\t\t\tsteps_per_epoch = len(self.trainer.fit_loop._data_source.dataloader())\n",
    "\n",
    "\t\t\n",
    "\t\ttotal_steps = self.trainer.max_epochs * steps_per_epoch\n",
    "\t\twarmup_steps = int(0.1 * total_steps) # 10% de pasos de warmup\n",
    "\n",
    "\t\t# Función que define el comportamiento del LR\n",
    "\t\tdef warmup_then_cosine(step):\n",
    "\t\t\tif step < warmup_steps: # fase de warmup\n",
    "\t\t\t\treturn step / max(1, warmup_steps)\n",
    "\t\t\tprogress = (step - warmup_steps) / max(1, total_steps - warmup_steps)\n",
    "\t\t\t# decaimiento coseno\n",
    "\t\t\treturn 0.5 * (1 + math.cos(math.pi * progress))\n",
    "\n",
    "\t\t# Selecciona el scheduler según configuración global\n",
    "\t\tif SCHEDULER == \"LambdaLR\":\n",
    "\t\t\tscheduler = LambdaLR(opt, lr_lambda=warmup_then_cosine)\n",
    "\t\telif SCHEDULER == \"CosineAnnealingLR\":\n",
    "\t\t\tscheduler = CosineAnnealingLR(opt, T_max=self.trainer.max_epochs)\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(f\"Scheduler desconocido: {SCHEDULER}\")\n",
    "\n",
    "\t\t# Devuelve optimizador y scheduler integrados en formato Lightning\n",
    "\t\treturn {\"optimizer\": opt, \"lr_scheduler\": {\"scheduler\": scheduler, \"interval\": \"step\"}}\n",
    "\n",
    "\t# ------------------------------------------------------------\n",
    "\t# Método para codificar señales sin entrenar (modo evaluación)\n",
    "\t# ------------------------------------------------------------\n",
    "\t@torch.no_grad()\n",
    "\tdef encode(self, x: torch.Tensor, normalize: bool = True) -> torch.Tensor:\n",
    "\t\th = self.encoder(x) # genera embedding\n",
    "\t\tif normalize: # opcionalmente lo normaliza\n",
    "\t\t\th = F.normalize(h, dim=1)\n",
    "\t\treturn h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efcac8b",
   "metadata": {},
   "source": [
    "### **6.7 Pre-Entrenamiento del Modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c131de9d",
   "metadata": {},
   "source": [
    "Este bloque de código entrena el modelo ``TimeCLR`` de forma auto-supervisada usando señales ECG:\n",
    "1. ``TimeCLRDataset`` y ``DataLoader``: Se crea un dataset (ssl_ds) con las señales X_train, aplicando la función de aumentación ecgtime_augment para generar vistas distintas de cada ejemplo. El DataLoader (ssl_dl) sirve para alimentar los lotes al modelo durante el entrenamiento contrastivo.\n",
    "2. ``TimeCLRModel``: Se instancia el modelo auto-supervisado con su encoder (ResNet1D) y cabeza de proyección, configurando hiperparámetros como la temperatura, LR y regularización.\n",
    "3. Entrenamiento con Trainer: Se configura un Trainer de PyTorch Lightning con GPU (si está disponible), mixed precision (float16), clipping de gradiente y monitoreo del learning rate. Luego se entrena (trainer.fit) el modelo con los datos aumentados (ssl_dl).\n",
    "4. encoder = timeclr_model.encoder.eval(): Al final, se extrae el encoder ya entrenado (sin la cabeza contrastiva) y se pone en modo evaluación (.eval()), listo para usarse en tareas supervisadas posteriores (por ejemplo, clasificación de ritmos cardíacos).\n",
    "\n",
    "En resumen: este código entrena un encoder auto-supervisado que aprende representaciones robustas de ECG sin usar etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dcddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset auto-supervisado (TimeCLR) con aumentaciones\n",
    "X_all_train = X_train\n",
    "ssl_ds = TimeCLRDataset(\n",
    "\tX=X_all_train,            # matrices de señales (N, T) o (N, 1, T)\n",
    "\ttransform=ecgtime_augment # función de augmentación temporal (jitter, crop, etc.)\n",
    ")\n",
    "\n",
    "# DataLoader para muestrear batches y barajarlos en cada época\n",
    "ssl_dl = DataLoader(\n",
    "\tssl_ds,\n",
    "\tbatch_size=BATCH_SSL,   # tamaño de lote para contraste\n",
    "\tshuffle=True,           # mezcla ejemplos cada época\n",
    "\tnum_workers=NUM_WORKERS # workers para cargar datos en paralelo\n",
    ")\n",
    "\n",
    "# Modelo TimeCLR: encoder (ResNet1D) + cabeza de proyección (MLP)\n",
    "timeclr_model = TimeCLRModel(\n",
    "\temb_dim=EMBEDDING_DIM, # dimensión del embedding del encoder\n",
    "\tproj_hid=PROJ_HID,     # ancho oculto del projector\n",
    "\tproj_out=PROJ_OUT,     # dim. del espacio contrastivo\n",
    "\ttemperature=TEMP,      # temperatura NT-Xent\n",
    "\tlr=LR_SSL,             # learning rate para AdamW\n",
    "\tweight_decay=WD        # regularización L2\n",
    ")\n",
    "\n",
    "# Cálculo auxiliar de pasos (para schedulers con warmup, monitoreo, etc.)\n",
    "steps_per_epoch = max(1, len(ssl_dl))\n",
    "warmup_steps = int(0.1 * EPOCHS_SSL * steps_per_epoch) # 10% de warmup\n",
    "lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval=\"step\") # registra LR por paso\n",
    "\n",
    "# Trainer de PyTorch Lightning: configura hardware, precisión y callbacks\n",
    "trainer = pl.Trainer(\n",
    "\tmax_epochs=EPOCHS_SSL,                                     # número de épocas SSL\n",
    "\taccelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\", # usa GPU si existe\n",
    "\tdevices=1,                                                 # una GPU/CPU\n",
    "\tprecision=\"16-mixed\" if torch.cuda.is_available() else 32, # mixed precision en GPU\n",
    "\tbenchmark=True,                                            # optimiza cudnn para tamaños fijos\n",
    "\tlog_every_n_steps=10,                                      # frecuencia de logging\n",
    "\tgradient_clip_val=1.0,                                     # evita exploding gradients\n",
    "\tcallbacks=[lr_monitor]                                     # callback para monitorear LR\n",
    ")\n",
    "\n",
    "# Ejecuta el loop de entrenamiento auto-supervisado\n",
    "trainer.fit(timeclr_model, ssl_dl)\n",
    "\n",
    "# Extrae el encoder ya preentrenado (sin projector) y lo pone en modo eval\n",
    "encoder = timeclr_model.encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dd6b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenamos el encoder entrenado\n",
    "encoder_path = f\"checkpoints/encoder_ssl.pt\"\n",
    "torch.save(encoder.state_dict(), encoder_path)\n",
    "print(f\"Encoder SSL guardado en: {encoder_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afb9ff3",
   "metadata": {},
   "source": [
    "### **6.8 LinearProbe**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83871da",
   "metadata": {},
   "source": [
    "Esta clase ``LinearProbe`` implementa la fase supervisada posterior al entrenamiento auto-supervisado (el linear probing). El objetivo es evaluar o ajustar el encoder aprendido (por ejemplo, de ``TimeCLR``) sin modificar sus pesos, añadiendo una cabeza lineal de clasificación entrenable encima.\n",
    "- init: Se recibe un encoder preentrenado (de ``TimeCLR``). Se congelan sus parámetros (requires_grad = False) para que no se actualicen. Se añade una capa de clasificación (``ClassifierHead``) que sí se entrena. Se define la función de pérdida (``CrossEntropy`` o ``FocalLoss``) y pesos de clase opcionales.\n",
    "- forward: Pasa el ECG por el encoder (sin gradientes) y luego por la cabeza clasificadora.\n",
    "- training_step, validation_step y test_step: Calcula la pérdida y métricas (accuracy, F1 macro, F1 por clase). Registra los resultados en PyTorch Lightning (self.log).\n",
    "- configure_optimizers: Usa ``AdamW`` solo para optimizar la cabeza clasificadora.\n",
    "\n",
    "En resumen: ``LinearProbe`` entrena una pequeña red clasificadora sobre un encoder congelado, permitiendo medir qué tan buena es la representación aprendida auto-supervisadamente para una tarea específica (por ejemplo, clasificación de arritmias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aae9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# LinearProbe: fase supervisada tras el preentrenamiento SSL\n",
    "# Entrena solo una \"cabeza\" de clasificación sobre un encoder congelado.\n",
    "# ============================================================\n",
    "class LinearProbe(pl.LightningModule):\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tencoder,                                  # encoder preentrenado (p. ej. TimeCLR)\n",
    "\t\tn_classes: int,                           # número de clases de salida\n",
    "\t\tlr: float = LR_LP,                        # learning rate\n",
    "\t\twd: float = WD,                           # weight decay (regularización L2)\n",
    "\t\tclass_weights: torch.Tensor | None = None # pesos por clase (opcional)\n",
    "\t):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.encoder = encoder\n",
    "\t\tself.lr, self.wd = lr, wd\n",
    "\t\tself.n_classes = n_classes\n",
    "\n",
    "\t\t# ------------------------------------------------------------\n",
    "\t\t# Congelamos los parámetros del encoder: no se actualizan\n",
    "\t\t# Solo se entrena la cabeza clasificadora\n",
    "\t\t# ------------------------------------------------------------\n",
    "\t\tfor p in self.encoder.parameters():\n",
    "\t\t\tp.requires_grad = False\n",
    "\t\t\n",
    "\t\t# Definimos la cabeza de clasificación (MLP con dropout)\n",
    "\t\tself.head = ClassifierHead(\n",
    "\t\t\tin_dim=EMBEDDING_DIM, # tamaño del embedding del encoder\n",
    "\t\t\thid=256,              # tamaño oculto intermedio\n",
    "\t\t\tn_classes=n_classes,  # clases de salida\n",
    "\t\t\tp_drop=0.4            # probabilidad de dropout\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\t# ------------------------------------------------------------\n",
    "\t\t# Guardamos pesos de clase (si existen) como buffer\n",
    "\t\t# Los buffers se mueven automáticamente a GPU/CPU con el modelo\n",
    "\t\t# ------------------------------------------------------------\n",
    "\t\tif class_weights is not None:\n",
    "\t\t\tself.register_buffer(\"class_weights\", class_weights.clone().float())\n",
    "\t\telse:\n",
    "\t\t\tself.class_weights = None\n",
    "\t\t\n",
    "\t\t# ------------------------------------------------------------\n",
    "\t\t# Selección de función de pérdida (definida globalmente)\n",
    "\t\t# ------------------------------------------------------------\n",
    "\t\tif LOSS_LP == \"FocalLoss\":\n",
    "\t\t\tself.criterion = self._focal_loss_lp\n",
    "\t\telif LOSS_LP == \"CrossEntropy\":\n",
    "\t\t\tself.criterion = self._ce_loss_lp\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(f\"Función de pérdida desconocida: {LOSS_LP}\")\n",
    "\n",
    "\t# ============================================================\n",
    "\t# Utilidad: devuelve los pesos de clase en el dispositivo correcto\n",
    "\t# ============================================================\n",
    "\tdef _get_weights(self, logits):\n",
    "\t\tif self.class_weights is None:\n",
    "\t\t\treturn None\n",
    "\t\treturn self.class_weights.to(device=logits.device, dtype=logits.dtype)\n",
    "\n",
    "\t# ============================================================\n",
    "\t# Definición de Focal Loss (versión local)\n",
    "\t# ============================================================\n",
    "\tdef _focal_loss_lp(self, logits, y):\n",
    "\t\tw = self._get_weights(logits)\n",
    "\t\treturn FocalLoss(\n",
    "\t\t\tgamma=GAMMA_LP,\n",
    "\t\t\tweight=w\n",
    "\t\t)(logits, y)\n",
    "\n",
    "\t# ============================================================\n",
    "\t# Definición de CrossEntropy Loss con label smoothing\n",
    "\t# ============================================================\n",
    "\tdef _ce_loss_lp(self, logits, y):\n",
    "\t\tw = self._get_weights(logits)\n",
    "\t\treturn F.cross_entropy(\n",
    "\t\t\tlogits,\n",
    "\t\t\ty,\n",
    "\t\t\t#weight=w,           # opcionalmente aplicar pesos\n",
    "\t\t\tlabel_smoothing=0.05 # suaviza etiquetas para mejor generalización\n",
    "\t\t)\n",
    "\n",
    "\t# ============================================================\n",
    "\t# Forward: pasa por el encoder congelado y luego por la cabeza\n",
    "\t# ============================================================\n",
    "\tdef forward(self, x):\n",
    "\t\twith torch.no_grad():   # evita gradientes en el encoder\n",
    "\t\t\th = self.encoder(x) # genera embeddings fijos\n",
    "\t\tlogits = self.head(h)   # los pasa por la cabeza de clasificación\n",
    "\t\treturn logits\n",
    "\n",
    "\t# ============================================================\n",
    "\t# Función auxiliar: calcula métricas por batch\n",
    "\t# ============================================================\n",
    "\tdef _compute_batch_metrics(self, logits, y, split: str):\n",
    "\t\t\"\"\"\n",
    "\t\tsplit: 'lp_train' o 'lp_val' para prefijar bien los nombres de logs.\n",
    "\t\t\"\"\"\n",
    "\t\tpred = logits.argmax(dim=1) # clase predicha\n",
    "\n",
    "\t\t# Accuracy promedio del batch\n",
    "\t\tacc = (pred == y).float().mean()\n",
    "\t\t\n",
    "\t\t# F1 por clase\n",
    "\t\tf1_per_class = []\n",
    "\t\tfor c in range(self.n_classes):\n",
    "\t\t\ttp = ((pred == c) & (y == c)).sum().float()\n",
    "\t\t\tfp = ((pred == c) & (y != c)).sum().float()\n",
    "\t\t\tfn = ((pred != c) & (y == c)).sum().float()\n",
    "\n",
    "\t\t\tprecision = tp / (tp + fp + 1e-8)\n",
    "\t\t\trecall = tp / (tp + fn + 1e-8)\n",
    "\t\t\tf1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "\t\t\tf1_per_class.append(f1)\n",
    "\n",
    "\t\t\t# Guarda F1 por clase en los logs de Lightning\n",
    "\t\t\tself.log(\n",
    "\t\t\t\tf\"{split}_f1_class_{c}\",\n",
    "\t\t\t\tf1,\n",
    "\t\t\t\ton_step=False,\n",
    "\t\t\t\ton_epoch=True,\n",
    "\t\t\t\tprog_bar=False,\n",
    "\t\t\t\tlogger=True,\n",
    "\t\t\t)\n",
    "\n",
    "\t\t# F1 macro: promedio de todas las clases\n",
    "\t\tf1_macro = torch.stack(f1_per_class).mean()\n",
    "\t\treturn acc, f1_macro\n",
    "\n",
    "\t# ============================================================\n",
    "\t# Paso de entrenamiento supervisado\n",
    "\t# ============================================================\n",
    "\tdef training_step(self, batch, _):\n",
    "\t\tx, y = batch\n",
    "\t\tlogits = self(x)\n",
    "\t\tloss = self.criterion(logits, y)\n",
    "\n",
    "\t\tacc, f1_macro = self._compute_batch_metrics(logits, y, split=\"lp_train\")\n",
    "\n",
    "\t\t# Registra métricas en Lightning (se muestran en barra/logs)\n",
    "\t\tself.log(\"lp_train_loss\", loss, prog_bar=True, on_step=True, on_epoch=True, logger=True)\n",
    "\t\tself.log(\"lp_train_acc\", acc, prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
    "\t\tself.log(\"lp_train_f1_macro\", f1_macro, prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
    "\n",
    "\t\treturn loss\n",
    "\t\n",
    "\t# ============================================================\n",
    "\t# Paso de validación\n",
    "\t# ============================================================\n",
    "\tdef validation_step(self, batch, _):\n",
    "\t\tx, y = batch\n",
    "\t\tlogits = self(x)\n",
    "\t\tloss = self.criterion(logits, y)\n",
    "\n",
    "\t\tacc, f1_macro = self._compute_batch_metrics(logits, y, split=\"lp_val\")\n",
    "\n",
    "\t\tself.log(\"lp_val_loss\", loss, prog_bar=True, on_step=True, on_epoch=True, logger=True)\n",
    "\t\tself.log(\"lp_val_acc\", acc, prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
    "\t\tself.log(\"lp_val_f1_macro\", f1_macro, prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
    "\n",
    "\t\treturn loss\n",
    "\n",
    "\t# ============================================================\n",
    "\t# Paso de testeo (solo calcula accuracy)\n",
    "\t# ============================================================\n",
    "\tdef test_step(self, batch, _):\n",
    "\t\tx, y = batch\n",
    "\t\tlogits = self(x)\n",
    "\t\tpred = logits.argmax(1)\n",
    "\t\tacc = (pred == y).float().mean()\n",
    "\t\tself.log(\"lp_test_acc\", acc, prog_bar=True)\n",
    "\n",
    "\t# ============================================================\n",
    "\t# Configura optimizador (solo entrena la cabeza)\n",
    "\t# ============================================================\n",
    "\tdef configure_optimizers(self):\n",
    "\t\treturn AdamW(self.head.parameters(), lr=self.lr, weight_decay=self.wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04230990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el encoder previamente almacenado\n",
    "encoder = ResNet1DBackbone(in_ch=1, emb_dim=EMBEDDING_DIM)\n",
    "encoder_path = \"checkpoints/encoder_ssl.pt\"\n",
    "encoder.load_state_dict(torch.load(encoder_path, map_location=\"cpu\"))\n",
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1effafd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1) División del dataset etiquetado en entrenamiento y validación\n",
    "# ============================================================\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "X_lab_train,                 # señales etiquetadas disponibles\n",
    "\ty_lab_train.astype(int), # etiquetas como enteros\n",
    "\ttest_size=0.25,          # % para validación\n",
    "\tstratify=y_lab_train,    # mantiene proporción de clases (estratificado)\n",
    "\trandom_state=SEED        # semilla para reproducibilidad\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Creación de datasets etiquetados para cada split\n",
    "# ============================================================\n",
    "train_ds = LabeledECGDataset(\n",
    "\tX_tr,\n",
    "\ty_tr,\n",
    "\ttransform=ecgtime_augment, # aplica augmentaciones al entrenamiento\n",
    "\tp_aug=0.7                  # probabilidad de aplicar augmentación\n",
    ")\n",
    "val_ds = LabeledECGDataset(X_val, y_val) # sin augmentación\n",
    "test_ds = LabeledECGDataset(X_test, y_test.astype(int)) # dataset final de testeo\n",
    "\n",
    "# ============================================================\n",
    "# 2) Cálculo de pesos por clase para balancear el sampler\n",
    "# ============================================================\n",
    "y_tr_np = y_tr.astype(int)\n",
    "class_counts_tr = np.bincount(y_tr_np, minlength=n_classes) # cuenta muestras por clase\n",
    "print(\"Cantidad por clase en y_tr (0..4):\", class_counts_tr)\n",
    "\n",
    "# Parámetro alpha controla el grado de balanceo\n",
    "alpha = 0.0\n",
    "# Inverso de la frecuencia por clase (controlado por alpha)\n",
    "inv_sampler = 1.0 / (class_counts ** alpha)\n",
    "# Normaliza los pesos para que su media sea 1\n",
    "class_weights_sampler = inv_sampler / inv_sampler.mean()\n",
    "print(\"Pesos por clase para SAMPLER (0..4):\", class_weights_sampler)\n",
    "\n",
    "# Asigna a cada muestra su peso según su clase\n",
    "sample_weights_np = class_weights_sampler[y_tr_np]\n",
    "sample_weights = torch.from_numpy(sample_weights_np).float()\n",
    "print(\"sample_weights shape:\", sample_weights.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 3) Creación de un WeightedRandomSampler para balancear las clases\n",
    "# ============================================================\n",
    "sampler = WeightedRandomSampler(\n",
    "\tweights=sample_weights,          # pesos calculados para cada muestra\n",
    "\tnum_samples=len(sample_weights), # tamaño total del set de entrenamiento\n",
    "\treplacement=True                 # permite repetir muestras (sampling con reemplazo)\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 4) DataLoaders: manejan los batches para entrenamiento y evaluación\n",
    "# ============================================================\n",
    "\n",
    "# --- Entrenamiento ---\n",
    "train_dl = DataLoader(\n",
    "\ttrain_ds,\n",
    "\tbatch_size=BATCH_LP,    # tamaño de batch para el LinearProbe\n",
    "\tsampler=sampler,        # usa el sampler balanceado en vez de shuffle\n",
    "\tshuffle=False,          # desactivado porque sampler ya decide el orden\n",
    "\tnum_workers=NUM_WORKERS # carga de datos en paralelo\n",
    ")\n",
    "\n",
    "# --- Validación ---\n",
    "val_dl = DataLoader(\n",
    "\tval_ds,\n",
    "\tbatch_size=BATCH_LP,\n",
    "\tshuffle=False,\n",
    "\tnum_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "# --- Testeo ---\n",
    "test_dl = DataLoader(\n",
    "\ttest_ds,\n",
    "\tbatch_size=BATCH_LP,\n",
    "\tshuffle=False,\n",
    "\tnum_workers=NUM_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b37b317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Callback de Early Stopping\n",
    "# ============================================================\n",
    "early_stop = EarlyStopping(\n",
    "\tmonitor=\"lp_val_f1_macro\", # métrica a monitorear (F1 macro en validación)\n",
    "\tmode=\"max\",                # queremos maximizar esta métrica\n",
    "\tpatience=8,                # número de épocas sin mejora antes de detener el entrenamiento\n",
    "\tmin_delta=1e-4             # cambio mínimo considerado como mejora\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Callback de Checkpointing\n",
    "# ============================================================\n",
    "checkpoint = ModelCheckpoint(\n",
    "\tmonitor=\"lp_val_f1_macro\",                       # métrica a monitorear\n",
    "\tmode=\"max\",                                      # guarda el modelo con mayor F1 macro\n",
    "\tsave_top_k=1,                                    # solo guarda el mejor modelo\n",
    "\tfilename=\"lp-best-{epoch}-{lp_val_f1_macro:.4f}\" # nombre del archivo guardado\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9feab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1) Instancia del modelo Linear Probe\n",
    "# ============================================================\n",
    "lp = LinearProbe(\n",
    "\tencoder=encoder,                 # encoder preentrenado (de TimeCLR, congelado)\n",
    "\tn_classes=n_classes,             # número de clases a predecir\n",
    "\tlr=LR_LP,                        # tasa de aprendizaje del clasificador\n",
    "\twd=WD,                           # regularización L2 (weight decay)\n",
    "\tclass_weights=class_weights_loss # pesos de clase para manejar desbalance\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 2) Configuración del Trainer de PyTorch Lightning\n",
    "# ============================================================\n",
    "trainer = pl.Trainer(\n",
    "\tmax_epochs=EPOCHS_LP,                                      # número máximo de épocas supervisadas\n",
    "\taccelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\", # usa GPU si existe\n",
    "\tdevices=1,                                                 # número de dispositivos (1 GPU o CPU)\n",
    "\tcallbacks=[early_stop, checkpoint]                         # callbacks para early stopping y guardado del mejor modelo\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 3) Entrenamiento con datos etiquetados (fase supervisada)\n",
    "# ============================================================\n",
    "trainer.fit(lp, train_dl, val_dl)\n",
    "\n",
    "# ============================================================\n",
    "# 4) Carga del mejor modelo según la métrica de validación\n",
    "# ============================================================\n",
    "best_lp = LinearProbe.load_from_checkpoint(\n",
    "\tcheckpoint.best_model_path,      # ruta al mejor checkpoint guardado\n",
    "\tencoder=encoder,                 # se vuelve a pasar el encoder\n",
    "\tn_classes=num_classes,           # número de clases\n",
    "\tlr=LR_LP,\n",
    "\twd=WD,\n",
    "\tclass_weights=class_weights_loss\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 5) Evaluación final (testeo)\n",
    "# ============================================================\n",
    "trainer.test(best_lp, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5968d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenamos nuestro linear probe entrenado\n",
    "linearprobe_path = f\"checkpoints/linearprobe_head_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.pt\"\n",
    "torch.save(lp.head.state_dict(), linearprobe_path)\n",
    "print(f\"Cabeza del LinearProbe guardada en: {linearprobe_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957dc00e",
   "metadata": {},
   "source": [
    "### **6.9 FineTuning TimeCLR**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ec2097",
   "metadata": {},
   "source": [
    "La clase FineTune implementa la fase de ajuste fino (fine-tuning) sobre el encoder preentrenado de TimeCLR. El objetivo es ajustar parcialmente el encoder (ya preentrenado de forma auto-supervisada) junto con una nueva cabeza de clasificación para mejorar el rendimiento en una tarea supervisada.\n",
    "\n",
    "Resumen de funcionamiento:\n",
    "- Recibe el encoder preentrenado y lo congela casi por completo, salvo su capa final (fc) si existe.\n",
    "- Agrega una cabeza clasificadora (ClassifierHead) con dropout y ReLU.\n",
    "- Define una función de pérdida (CrossEntropy o FocalLoss) y soporta pesos por clase.\n",
    "- Durante el entrenamiento (training_step, validation_step, test_step), calcula la pérdida y métricas (accuracy, F1 macro y por clase).\n",
    "- Usa un optimizador AdamW con dos grupos de parámetros:\n",
    "\t- uno para el encoder (con lr_enc, tasa baja)\n",
    "\t- otro para la cabeza (lr_head, tasa más alta).\n",
    "- Aplica un scheduler CosineAnnealingLR para decaer gradualmente el learning rate.\n",
    "\n",
    "En resumen: esta clase entrena el modelo completo (encoder + cabeza), pero con aprendizaje diferencial, refinando solo ciertas partes del encoder — una etapa típica posterior al Linear Probe dentro del flujo semi-supervisado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f56566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FineTune: fase de ajuste fino del modelo preentrenado\n",
    "# ============================================================\n",
    "# A diferencia del LinearProbe, aquí parte del encoder puede actualizarse,\n",
    "# para adaptar mejor las representaciones auto-supervisadas a la tarea final.\n",
    "# ============================================================\n",
    "class FineTune(pl.LightningModule):\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tencoder,                                  # encoder preentrenado (de TimeCLR)\n",
    "\t\tn_classes: int,                           # número de clases de salida\n",
    "\t\tlr_enc=LR_FT_ENC,                         # learning rate para el encoder\n",
    "\t\tlr_head=LR_FT_HEAD,                       # learning rate para la cabeza\n",
    "\t\twd=WD,                                    # weight decay (regularización L2)\n",
    "\t\tclass_weights: torch.Tensor | None = None # pesos opcionales por clase\n",
    "\t):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.encoder = encoder\n",
    "\t\tself.lr_enc, self.lr_head, self.wd = lr_enc, lr_head, wd\n",
    "\t\tself.n_classes = n_classes\n",
    "\n",
    "\t\t# ------------------------------------------------------------\n",
    "\t\t# Congela todo el encoder, excepto su capa final \"fc\" (si existe)\n",
    "\t\t# Esto permite refinar parcialmente las representaciones aprendidas\n",
    "\t\t# ------------------------------------------------------------\n",
    "\t\tfor p in self.encoder.parameters():\n",
    "\t\t\tp.requires_grad = False\n",
    "\t\tif hasattr(self.encoder, \"fc\"):\n",
    "\t\t\tfor p in self.encoder.fc.parameters():\n",
    "\t\t\t\tp.requires_grad = True\n",
    "\n",
    "\t\t# Crea la cabeza de clasificación (MLP con normalización y dropout)\n",
    "\t\tself.head = ClassifierHead(\n",
    "\t\t\tin_dim=EMBEDDING_DIM,\n",
    "\t\t\thid=256,\n",
    "\t\t\tn_classes=n_classes,\n",
    "\t\t\tp_drop=0.4\n",
    "\t\t)\n",
    "\n",
    "\t\t# Guarda los pesos de clase como buffer (se mueven con el modelo a GPU/CPU)\n",
    "\t\tif class_weights is not None:\n",
    "\t\t\tself.register_buffer(\"class_weights\", class_weights.clone().float())\n",
    "\t\telse:\n",
    "\t\t\tself.class_weights = None\n",
    "\t\t\n",
    "\t\t# Selecciona la función de pérdida (Focal o CrossEntropy)\n",
    "\t\tif LOSS_FN == \"FocalLoss\":\n",
    "\t\t\tself.criterion = self._focal_loss_ft\n",
    "\t\telif LOSS_FN == \"CrossEntropy\":\n",
    "\t\t\tself.criterion = self._ce_loss_ft\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(f\"Función de pérdida desconocida: {LOSS_FN}\")\n",
    "\n",
    "\t# ============================================================\n",
    "\t# Obtiene los pesos de clase en el dispositivo adecuado\n",
    "\t# ============================================================\n",
    "\tdef _get_weights(self, logits):\n",
    "\t\tif self.class_weights is None:\n",
    "\t\t\treturn None\n",
    "\t\treturn self.class_weights.to(device=logits.device, dtype=logits.dtype)\n",
    "\n",
    "\t# ============================================================\n",
    "\t# Focal Loss: da más peso a ejemplos difíciles\n",
    "\t# ============================================================\n",
    "\tdef _focal_loss_ft(self, logits, y):\n",
    "\t\tw = self._get_weights(logits)\n",
    "\t\treturn FocalLoss(\n",
    "\t\t\tgamma=GAMMA_FN,\n",
    "\t\t\t#weight=w\n",
    "\t\t)(logits, y)\n",
    "\n",
    "\t# ============================================================\n",
    "\t# Cross Entropy Loss con label smoothing (suaviza etiquetas)\n",
    "\t# ============================================================\n",
    "\tdef _ce_loss_ft(self, logits, y):\n",
    "\t\tw = self._get_weights(logits)\n",
    "\t\treturn F.cross_entropy(\n",
    "\t\t\tlogits,\n",
    "\t\t\ty,\n",
    "\t\t\t#weight=w,           # opcionalmente aplicar pesos\n",
    "\t\t\tlabel_smoothing=0.05 # suaviza etiquetas para mejor generalización\n",
    "\t\t)\n",
    "\n",
    "\t# ============================================================\n",
    "\t# Forward: pasa por encoder + cabeza clasificadora\n",
    "\t# ============================================================\n",
    "\tdef forward(self, x):\n",
    "\t\th = self.encoder(x)   # extrae embeddings\n",
    "\t\tlogits = self.head(h) # produce logits de clase\n",
    "\t\treturn logits\n",
    "\n",
    "\t# ============================================================\n",
    "\t# Cálculo de métricas por batch (accuracy, F1 macro, F1 por clase)\n",
    "\t# ============================================================\n",
    "\tdef _compute_batch_metrics(self, logits, y, split: str):\n",
    "\t\t\"\"\"\n",
    "\t\tsplit: 'ft_train', 'ft_val' o 'ft_test' para prefijar bien los nombres de logs.\n",
    "\t\t\"\"\"\n",
    "\t\tpred = logits.argmax(dim=1) # clase predicha\n",
    "\n",
    "\t\tacc = (pred == y).float().mean() # accuracy promedio\n",
    "\n",
    "\t\tf1_per_class = []\n",
    "\t\tfor c in range(self.n_classes):\n",
    "\t\t\ttp = ((pred == c) & (y == c)).sum().float()\n",
    "\t\t\tfp = ((pred == c) & (y != c)).sum().float()\n",
    "\t\t\tfn = ((pred != c) & (y == c)).sum().float()\n",
    "\n",
    "\t\t\tprecision = tp / (tp + fp + 1e-8)\n",
    "\t\t\trecall = tp / (tp + fn + 1e-8)\n",
    "\t\t\tf1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "\t\t\tf1_per_class.append(f1)\n",
    "\n",
    "\t\t\t# Guarda F1 por clase en los logs\n",
    "\t\t\tself.log(\n",
    "\t\t\t\tf\"{split}_f1_class_{c}\",\n",
    "\t\t\t\tf1,\n",
    "\t\t\t\ton_step=False,\n",
    "\t\t\t\ton_epoch=True,\n",
    "\t\t\t\tprog_bar=False,\n",
    "\t\t\t\tlogger=True,\n",
    "\t\t\t)\n",
    "\n",
    "\t\tf1_macro = torch.stack(f1_per_class).mean() # promedio (macro)\n",
    "\t\treturn acc, f1_macro\n",
    "\t\n",
    "\t# ============================================================\n",
    "\t# Paso de entrenamiento\n",
    "\t# ============================================================\n",
    "\tdef training_step(self, batch, _):\n",
    "\t\tx, y = batch\n",
    "\t\tlogits = self(x)\n",
    "\t\tloss = self.criterion(logits, y)\n",
    "\n",
    "\t\tacc, f1_macro = self._compute_batch_metrics(logits, y, split=\"ft_train\")\n",
    "\n",
    "\t\tself.log(\"ft_train_loss\", loss, prog_bar=True, on_step=True, on_epoch=True, logger=True)\n",
    "\t\tself.log(\"ft_train_acc\", acc, prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
    "\t\tself.log(\"ft_train_f1_macro\", f1_macro, prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
    "\n",
    "\t\treturn loss\n",
    "\n",
    "\t# ============================================================\n",
    "\t# Paso de validación\n",
    "\t# ============================================================\n",
    "\tdef validation_step(self, batch, _):\n",
    "\t\tx, y = batch\n",
    "\t\tlogits = self(x)\n",
    "\t\tloss = self.criterion(logits, y)\n",
    "\n",
    "\t\tacc, f1_macro = self._compute_batch_metrics(logits, y, split=\"ft_val\")\n",
    "\n",
    "\t\tself.log(\"ft_val_loss\", loss, prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
    "\t\tself.log(\"ft_val_acc\", acc, prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
    "\t\tself.log(\"ft_val_f1_macro\", f1_macro, prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
    "\t\t\n",
    "\t\treturn loss\n",
    "\n",
    "\t# ============================================================\n",
    "\t# Paso de testeo\n",
    "\t# ============================================================\n",
    "\tdef test_step(self, batch, _):\n",
    "\t\tx, y = batch\n",
    "\t\tlogits = self(x)\n",
    "\t\tloss = self.criterion(logits, y)\n",
    "\n",
    "\t\tacc, f1_macro = self._compute_batch_metrics(logits, y, split=\"ft_test\")\n",
    "\n",
    "\t\tself.log(\"ft_test_loss\", loss, prog_bar=False, on_step=False, on_epoch=True)\n",
    "\t\tself.log(\"ft_test_acc\", acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\t\tself.log(\"ft_test_f1_macro\", f1_macro, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "\t\treturn loss\n",
    "\n",
    "\t# ============================================================\n",
    "\t# Configura optimizador y scheduler\n",
    "\t# ============================================================\n",
    "\tdef configure_optimizers(self):\n",
    "\t\tenc_params = [p for p in self.encoder.parameters() if p.requires_grad]\n",
    "\t\thead_params = [p for p in self.head.parameters() if p.requires_grad]\n",
    "\n",
    "\t\tparam_groups = []\n",
    "\t\tif len(enc_params) > 0:\n",
    "\t\t\tparam_groups.append({\n",
    "\t\t\t\t\"params\": enc_params,\n",
    "\t\t\t\t\"lr\": self.lr_enc,\n",
    "\t\t\t\t\"weight_decay\": self.wd,\n",
    "\t\t\t})\n",
    "\t\tif len(head_params) > 0:\n",
    "\t\t\tparam_groups.append({\n",
    "\t\t\t\t\"params\": head_params,\n",
    "\t\t\t\t\"lr\": self.lr_head,\n",
    "\t\t\t\t\"weight_decay\": self.wd,\n",
    "\t\t\t})\n",
    "\t\t\n",
    "\t\t# Optimizador AdamW con los dos grupos de parámetros\n",
    "\t\topt = AdamW(param_groups)\n",
    "\n",
    "\t\t# Scheduler: reduce LR suavemente con CosineAnnealing\n",
    "\t\tsch = CosineAnnealingLR(opt, T_max=EPOCHS_FT)\n",
    "\t\t\n",
    "\t\treturn {\"optimizer\": opt, \"lr_scheduler\": sch}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c192949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1) División del dataset etiquetado en entrenamiento y validación\n",
    "# ============================================================\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "\tX_lab_train,          # señales ECG etiquetadas disponibles\n",
    "\ty_lab_train,          # etiquetas correspondientes\n",
    "\ttest_size=0.25,       # % de los datos de reserva para validación\n",
    "\tstratify=y_lab_train, # mantiene la proporción de clases (balance estratificado)\n",
    "\trandom_state=SEED     # semilla para reproducibilidad\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 2) WeightedRandomSampler para entrenamiento balanceado\n",
    "# ============================================================\n",
    "sampler = WeightedRandomSampler(\n",
    "\tweights=sample_weights,          # pesos asociados a cada muestra\n",
    "\tnum_samples=len(sample_weights), # cantidad total de ejemplos a muestrear\n",
    "\treplacement=True                 # con reemplazo (permite repetir ejemplos raros)\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 3) DataLoader de entrenamiento (Fine-Tuning)\n",
    "# ============================================================\n",
    "dl_tr = DataLoader(\n",
    "\tLabeledECGDataset(X_tr, y_tr, transform=ecgtime_augment, p_aug=0.7),\n",
    "\tbatch_size=BATCH_FT,    # tamaño del lote\n",
    "\tsampler=sampler,        # sampler balanceado (en vez de shuffle)\n",
    "\tshuffle=False,          # no se usa shuffle cuando hay sampler\n",
    "\tnum_workers=NUM_WORKERS # hilos paralelos para carga de datos\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 4) DataLoader de validación (Fine-Tuning)\n",
    "# ============================================================\n",
    "dl_val = DataLoader(\n",
    "\tLabeledECGDataset(X_val, y_val),\n",
    "\tbatch_size=BATCH_FT,\n",
    "\tshuffle=False,\n",
    "\tnum_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 5) DataLoader de testeo (Fine-Tuning)\n",
    "# ============================================================\n",
    "dl_te = DataLoader(\n",
    "\ttest_ds,\n",
    "\tbatch_size=BATCH_FT,\n",
    "\tshuffle=False,\n",
    "\tnum_workers=NUM_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26b4cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Callback de Early Stopping\n",
    "# ============================================================\n",
    "early_stop = pl.callbacks.EarlyStopping(\n",
    "\tmonitor=\"ft_val_f1_macro\", # métrica que se va a monitorear (F1 macro en validación)\n",
    "\tmode=\"max\",                # se busca maximizar esta métrica\n",
    "\tpatience=6                 # número de épocas sin mejora antes de detener el entrenamiento\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Callback de Checkpoint (guardado automático del mejor modelo)\n",
    "# ============================================================\n",
    "ckpt = pl.callbacks.ModelCheckpoint(\n",
    "\tmonitor=\"ft_val_f1_macro\", # métrica usada para decidir cuál modelo guardar\n",
    "\tmode=\"max\",                # guarda el modelo con el mayor F1 macro\n",
    "\tsave_top_k=1               # mantiene solo el mejor checkpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e36cd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1) Instanciación del modelo FineTune\n",
    "# ============================================================\n",
    "ft = FineTune(\n",
    "\tencoder=encoder,                 # encoder preentrenado de TimeCLR (ResNet1D)\n",
    "\tn_classes=n_classes,             # número de clases de salida\n",
    "\tlr_enc=LR_FT_ENC,                # learning rate para el encoder\n",
    "\tlr_head=LR_FT_HEAD,              # learning rate para la cabeza\n",
    "\twd=WD,                           # regularización L2 (weight decay)\n",
    "\tclass_weights=class_weights_loss # pesos por clase (para manejar desbalance)\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 2) Configuración del Trainer de PyTorch Lightning\n",
    "# ============================================================\n",
    "trainer = pl.Trainer(\n",
    "\tmax_epochs=EPOCHS_FT,                                      # número máximo de épocas de Fine-Tuning\n",
    "\taccelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\", # usa GPU si está disponible\n",
    "\tdevices=1,                                                 # número de dispositivos (1 GPU o CPU)\n",
    "\tcallbacks=[early_stop, ckpt]                               # callbacks: EarlyStopping + ModelCheckpoint\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 3) Inicialización de la cabeza del FineTune con pesos del LinearProbe\n",
    "# ============================================================\n",
    "linearprobe_path = \"checkpoints/linearprobe_head.pt\"\n",
    "ft.head.load_state_dict(torch.load(linearprobe_path, map_location=\"cpu\"))\n",
    "print(\"FineTune.head inicializada desde LinearProbe\")\n",
    "\n",
    "# ============================================================\n",
    "# 4) Entrenamiento supervisado (Fine-Tuning)\n",
    "# ============================================================\n",
    "trainer.fit(ft, dl_tr, dl_val)\n",
    "\n",
    "# ============================================================\n",
    "# 5) Evaluación final en el conjunto de testeo\n",
    "# ============================================================\n",
    "trainer.test(ft, dl_te)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8859ae8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenamos nuestro modelo con fine tuning\n",
    "finetune_path = f\"checkpoints/finetune_best.ckpt\"\n",
    "trainer.save_checkpoint(finetune_path)\n",
    "print(f\"Modelo FineTune guardado en: {finetune_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb4745b",
   "metadata": {},
   "source": [
    "### **6.10 Evaluación del Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ba8627",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_all_metrics(\n",
    "\tmodel: torch.nn.Module,\n",
    "\tdataloader,\n",
    "\tnum_classes: int,\n",
    "\tclass_names: Optional[List[str]] = None,\n",
    "\tdevice: Optional[torch.device] = None,\n",
    "\tnormalize_cm: bool = True\n",
    ") -> Dict[str, object]:\n",
    "\tmodel.eval()\n",
    "\tif device is None:\n",
    "\t\tdevice = next(model.parameters()).device\n",
    "\n",
    "\tall_preds = []\n",
    "\tall_probs = []\n",
    "\tall_true  = []\n",
    "\n",
    "\tfor batch in dataloader:\n",
    "\t\tif isinstance(batch, (list, tuple)) and len(batch) == 2:\n",
    "\t\t\tx, y = batch\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(\"Dataloader debe entregar (x, y).\")\n",
    "\n",
    "\t\tx = x.to(device)\n",
    "\t\ty = y.to(device)\n",
    "\n",
    "\t\tlogits = model(x)\n",
    "\t\tprobs  = F.softmax(logits, dim=1)\n",
    "\t\tpreds  = probs.argmax(1)\n",
    "\n",
    "\t\tall_true.append(y.cpu().numpy())\n",
    "\t\tall_preds.append(preds.cpu().numpy())\n",
    "\t\tall_probs.append(probs.cpu().numpy())\n",
    "\n",
    "\ty_true = np.concatenate(all_true, axis=0)\n",
    "\ty_pred = np.concatenate(all_preds, axis=0)\n",
    "\ty_prob = np.concatenate(all_probs, axis=0)\n",
    "\n",
    "\tacc     = accuracy_score(y_true, y_pred)\n",
    "\tf1_mac  = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "\trec_per_class = recall_score(y_true, y_pred, average=None, labels=np.arange(num_classes), zero_division=0)\n",
    "\n",
    "\ttarget_names = class_names if (class_names is not None and len(class_names) == num_classes) else None\n",
    "\tcls_report = classification_report(\n",
    "\t\ty_true, y_pred,\n",
    "\t\ttarget_names=target_names,\n",
    "\t\tzero_division=0,\n",
    "\t\tdigits=4\n",
    "\t)\n",
    "\n",
    "\tcm = confusion_matrix(y_true, y_pred, labels=np.arange(num_classes))\n",
    "\tif normalize_cm:\n",
    "\t\twith np.errstate(all=\"ignore\"):\n",
    "\t\t\tcm_norm = cm / cm.sum(axis=1, keepdims=True)\n",
    "\t\t\tcm_norm = np.nan_to_num(cm_norm)\n",
    "\telse:\n",
    "\t\tcm_norm = None\n",
    "\n",
    "\troc_auc_macro = None\n",
    "\ttry:\n",
    "\t\tunique_test_classes = np.unique(y_true)\n",
    "\t\tif num_classes == 2:\n",
    "\t\t\tif set(unique_test_classes.tolist()) == {0, 1}:\n",
    "\t\t\t\troc_auc_macro = roc_auc_score(y_true, y_prob[:, 1])\n",
    "\t\t\telse:\n",
    "\t\t\t\tclasses_sorted = np.sort(unique_test_classes)\n",
    "\t\t\t\tmapper = {c:i for i, c in enumerate(classes_sorted)}\n",
    "\t\t\t\ty_true_bin = np.vectorize(mapper.get)(y_true)\n",
    "\t\t\t\tpos_index = np.where(classes_sorted == classes_sorted.max())[0][0]\n",
    "\t\t\t\troc_auc_macro = roc_auc_score(y_true_bin, y_prob[:, pos_index])\n",
    "\t\telse:\n",
    "\t\t\tif len(unique_test_classes) >= 2:\n",
    "\t\t\t\troc_auc_macro = roc_auc_score(y_true, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "\t\t\telse:\n",
    "\t\t\t\troc_auc_macro = None\n",
    "\texcept Exception as e:\n",
    "\t\troc_auc_macro = None\n",
    "\n",
    "\tresults = {\n",
    "\t\t\"f1_macro\": f1_mac,\n",
    "\t\t\"accuracy\": acc,\n",
    "\t\t\"recall_per_class\": rec_per_class,\n",
    "\t\t\"confusion_matrix\": cm,\n",
    "\t\t\"confusion_matrix_normalized\": cm_norm,\n",
    "\t\t\"roc_auc_macro\": roc_auc_macro,\n",
    "\t\t\"classification_report\": cls_report,\n",
    "\t}\n",
    "\n",
    "\t# Impresión amigable\n",
    "\tprint(\"\\n=== Evaluación ===\")\n",
    "\tprint(f\"F1-macro: {f1_mac:.4f}\")\n",
    "\tprint(f\"Accuracy: {acc:.4f}\")\n",
    "\tif roc_auc_macro is not None:\n",
    "\t\tprint(f\"ROC-AUC macro (OVR): {roc_auc_macro:.4f}\")\n",
    "\telse:\n",
    "\t\tprint(\"ROC-AUC macro: no disponible (clases ausentes o caso no válido).\")\n",
    "\n",
    "\tprint(\"\\nRecall por clase:\")\n",
    "\tif target_names is not None:\n",
    "\t\tfor i, r in enumerate(rec_per_class):\n",
    "\t\t\tprint(f\"  {target_names[i]}: {r:.4f}\")\n",
    "\telse:\n",
    "\t\tfor i, r in enumerate(rec_per_class):\n",
    "\t\t\tprint(f\"  clase {i}: {r:.4f}\")\n",
    "\n",
    "\tprint(\"\\nReporte por clase:\\n\", cls_report)\n",
    "\tprint(\"Matriz de confusión (cruda):\\n\", cm)\n",
    "\tif cm_norm is not None:\n",
    "\t\tprint(\"Matriz de confusión (normalizada por fila):\\n\", np.round(cm_norm, 4))\n",
    "\n",
    "\treturn results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2211a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = int(np.unique(y_train[~np.isnan(y_train).astype(bool)]).size) if hasattr(y_train, \"dtype\") else int(np.unique(y_train).size)\n",
    "\n",
    "class_names = [\n",
    "\t\"(N) Latido normal\",\n",
    "\t\"(S) Latido supraventricular\",\n",
    "\t\"(V) Latido ventricular ectópico\",\n",
    "\t\"(F) Latido de fusión\",\n",
    "\t\"(Q) Latido desconocido\"\n",
    "]\n",
    "\n",
    "results = evaluate_all_metrics(\n",
    "\tmodel=ft,\n",
    "\tdataloader=test_dl,\n",
    "\tnum_classes=num_classes,\n",
    "\tclass_names=class_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f90a02",
   "metadata": {},
   "source": [
    "### **6.11 Threshold Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4533e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modo evaluación\n",
    "ft.eval()\n",
    "ft.to(DEVICE)\n",
    "\n",
    "# Recolectar probabilidades y etiquetas verdaderas del conjunto de validación\n",
    "all_logits, all_y = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "\tfor x, y in val_dl:\n",
    "\t\tx = x.to(DEVICE)\n",
    "\t\tlogits = ft(x)\n",
    "\t\tall_logits.append(logits.cpu())\n",
    "\t\tall_y.append(y.cpu())\n",
    "\n",
    "all_logits = torch.cat(all_logits)\n",
    "all_y = torch.cat(all_y).numpy()\n",
    "\n",
    "# Softmax → Probabilidades por clase\n",
    "probs = torch.softmax(all_logits, dim=1).numpy()\n",
    "n_classes = probs.shape[1]\n",
    "\n",
    "# Buscar el mejor threshold por clase (maximizando F1)\n",
    "best_thresholds = np.ones(n_classes) * 0.5  # inicial\n",
    "for c in range(n_classes):\n",
    "\tbest_f1, best_th = 0.0, 0.5\n",
    "\tfor th in np.linspace(0.3, 0.9, 25):  # recorre valores posibles\n",
    "\t\tpred_c = (probs[:, c] >= th).astype(int)\n",
    "\t\ttrue_c = (all_y == c).astype(int)\n",
    "\t\tf1_c = f1_score(true_c, pred_c)\n",
    "\t\tif f1_c > best_f1:\n",
    "\t\t\tbest_f1, best_th = f1_c, th\n",
    "\tbest_thresholds[c] = best_th\n",
    "\tprint(f\"Clase {c}: threshold óptimo = {best_th:.3f}, F1 = {best_f1:.3f}\")\n",
    "\n",
    "print(\"\\nUmbrales óptimos por clase:\", np.round(best_thresholds, 3))\n",
    "\n",
    "# Función para aplicar los thresholds a las predicciones\n",
    "def predict_with_thresholds(probs, thresholds):\n",
    "\tadjusted = probs - thresholds[None, :]\n",
    "\treturn adjusted.argmax(axis=1)\n",
    "\n",
    "# Aplicar y evaluar con thresholds óptimos\n",
    "y_pred = predict_with_thresholds(probs, best_thresholds)\n",
    "\n",
    "print(\"\\n=== Evaluación con THRESHOLDS ajustados ===\")\n",
    "print(classification_report(all_y, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b459987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar thresholds para test/inferencia futura\n",
    "best_thresholds_path = f\"checkpoints/best_thresholds_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.npy\"\n",
    "np.save(best_thresholds_path, best_thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c312e7",
   "metadata": {},
   "source": [
    "### **6.12 Escritura en CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b8eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def write_predictions_csv(model, test_dl, thresholds_path=\"best_thresholds.npy\", out_path=\"preds.csv\"):\n",
    "\tmodel.eval()\n",
    "\tdevice = next(model.parameters()).device\n",
    "\n",
    "\t# Cargar thresholds ajustados\n",
    "\tthresholds = np.load(thresholds_path)\n",
    "\tprint(\"Umbrales cargados:\", np.round(thresholds, 3))\n",
    "\n",
    "\tids = []\n",
    "\tpreds = []\n",
    "\trunning_id = 0\n",
    "\n",
    "\tfor batch in test_dl:\n",
    "\t\tif isinstance(batch, (list, tuple)) and len(batch) >= 1:\n",
    "\t\t\tx = batch[0]\n",
    "\t\telse:\n",
    "\t\t\tx = batch\n",
    "\n",
    "\t\tbsz = x.size(0)\n",
    "\t\tx = x.to(device)\n",
    "\n",
    "\t\t# Probabilidades por clase\n",
    "\t\tlogits = model(x)\n",
    "\t\tp = F.softmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "\t\t# Aplicar thresholds por clase\n",
    "\t\tadjusted = p - thresholds[None, :]\n",
    "\t\tyhat = adjusted.argmax(axis=1)\n",
    "\n",
    "\t\tids.extend(range(running_id, running_id + bsz))\n",
    "\t\tpreds.extend(yhat.tolist())\n",
    "\t\trunning_id += bsz\n",
    "\n",
    "\tdf = pd.DataFrame({\"ID\": ids, \"label\": preds})\n",
    "\tdf.to_csv(out_path, index=False)\n",
    "\tprint(f\"CSV de predicciones guardado en: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0366a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_predictions_csv(\n",
    "\tft,\n",
    "\ttest_dl,\n",
    "\tthresholds_path=\"checkpoints/best_thresholds.npy\",\n",
    "\tout_path=f\"ecg_submittions/timeclr_predictions_thresholded_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.csv\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
