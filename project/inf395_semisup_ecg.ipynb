{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb6318f9",
   "metadata": {},
   "source": [
    "# Detectar arritmias cardíacas mediante señales de ECG parcialmente etiquetadas\n",
    "### INF395 Introducción a las Redes Neuronales and Deep Learning\n",
    "- Estudiante: Alessandro Bruno Cintolesi Rodríguez\n",
    "- ROL: 202173541-0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbd52dd",
   "metadata": {},
   "source": [
    "## **1. Librerias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf7341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === General / Utilidad ===\n",
    "from datetime import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Optional, Dict\n",
    "\n",
    "# === PyTorch, PyTorch Lightning, Torchvision ===\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import LambdaLR, CosineAnnealingLR\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# === Scikit-learn ===\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import (\n",
    "\tf1_score, accuracy_score, recall_score, confusion_matrix,\n",
    "\troc_auc_score, classification_report\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1f52b9",
   "metadata": {},
   "source": [
    "## **2. Variables globales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c09c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clases\n",
    "CLASSES = {\n",
    "\t0: \"(N) Latido normal\",\n",
    "\t1: \"(S) Latido supraventricular\",\n",
    "\t2: \"(V) Latido ventricular ectópico\",\n",
    "\t3: \"(F) Latido de fusión\",\n",
    "\t4: \"(Q) Latido desconocido\"\n",
    "}\n",
    "\n",
    "# Hiperparámetros revisados\n",
    "SEED = 42\n",
    "SIGNALS = 187\n",
    "EMBEDDING_DIM = 256\n",
    "PROJ_HID = 256\n",
    "PROJ_OUT = 128\n",
    "\n",
    "NUM_WORKERS = 0\n",
    "BATCH_SSL = 512\n",
    "BATCH_LP = 256\n",
    "BATCH_FT = 256\n",
    "\n",
    "EPOCHS_SSL = 100\n",
    "EPOCHS_LP = 25\n",
    "EPOCHS_FT = 40\n",
    "\n",
    "LR_SSL = 1e-3\n",
    "LR_LP = 2e-3\n",
    "LR_FT_HEAD = 1e-3\n",
    "LR_FT_ENC = 1e-4\n",
    "\n",
    "WD = 1e-4\n",
    "TEMP = 0.15\n",
    "\n",
    "ArrayLike = np.ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f3668c",
   "metadata": {},
   "source": [
    "## **3. Setup del Dispositivo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3734d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seteamos la semilla\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "pl.seed_everything(SEED, workers=True)\n",
    "\n",
    "# Seteamos el dispositivo\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(\"Using device:\", DEVICE)\n",
    "if DEVICE.type == \"cuda\":\n",
    "\tprint(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc21d6a",
   "metadata": {},
   "source": [
    "## **4. Funciones Auxiliares**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e43bfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ecg(X, y, aug=False, aug_title=\"\"):\n",
    "\ty_class = CLASSES.get(y, \"Sin clasificar\")\n",
    "\ttitle = f\"ECG Clase: {y_class}\"\n",
    "\tif aug:\n",
    "\t\ttitle = title + f\" | {aug_title}\"\n",
    "\n",
    "\tplt.plot(X)\n",
    "\tplt.title(title)\n",
    "\tplt.xlabel(\"Tiempo (muestras)\")\n",
    "\tplt.ylabel(\"Amplitud\")\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d824df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(X, clusters, n_clusters):\n",
    "\tfor i in range(n_clusters):\n",
    "\t\tcluster_mask = clusters == i\n",
    "\t\tcluster_mean = X[cluster_mask].mean(axis=0)\n",
    "\t\tplt.plot(cluster_mean, label=f\"Cluster {i}\")\n",
    "\n",
    "\tplt.legend()\n",
    "\tplt.title(\"Promedio de señal por cluster\")\n",
    "\tplt.xlabel(\"Muestra\")\n",
    "\tplt.ylabel(\"Amplitud promedio\")\n",
    "\tplt.grid(True)\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eb03a0",
   "metadata": {},
   "source": [
    "## **5. Analisis Exploratorio de Datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccab637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos nuestros datos desde los CSV\n",
    "train_df = pd.read_csv(\"ecg_signals/train_semi_supervised.csv\")\n",
    "test_df = pd.read_csv(\"ecg_signals/test_semi_supervised.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b9c497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos nuestros datos en X (serie de tiempo) / y (label)\n",
    "X_train = train_df.iloc[:, :-1].values\n",
    "y_train = train_df.iloc[:, -1].values\n",
    "\n",
    "X_test = test_df.iloc[:, 1:-1].values\n",
    "y_test = test_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3b2e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos nuestros datos de entrenamiento por etiquetados (labeled) y no etiquetados (unlabeled)\n",
    "y_train_np = np.asarray(y_train)\n",
    "mask_unl = np.isnan(y_train_np.astype(float, copy=False)) if y_train_np.dtype.kind in \"fc\" else np.zeros_like(y_train_np, dtype=bool)\n",
    "mask_unl |= (y_train_np == -1)\n",
    "\n",
    "mask_lab = ~mask_unl\n",
    "\n",
    "X_lab_train = X_train[mask_lab]\n",
    "y_lab_train = y_train_np[mask_lab].astype(int)\n",
    "X_unl_train = X_train[mask_unl]\n",
    "\n",
    "num_classes = int(np.unique(y_lab_train).size)\n",
    "T = X_train.shape[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1503191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficando un ECG\n",
    "plot_ecg(X=X_train[1], y=y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88197911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clusters con K-means\n",
    "train_kmeans = KMeans(n_clusters=5, random_state=SEED)\n",
    "train_clusters = train_kmeans.fit_predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f6a4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(X=X_train, clusters=train_clusters, n_clusters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e3f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un conteo por clases\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for c, n in zip(unique, counts):\n",
    "\tif not np.isnan(c):\n",
    "\t\tc = int(c)\n",
    "\tprint(f\"Clase {c}: {n} muestras ({n/len(y_train)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb4c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 5\n",
    "\n",
    "y_valid = y_train[~np.isnan(y_train)]\n",
    "y_valid = y_valid[y_valid >= 0].astype(int)\n",
    "\n",
    "print(\"Clases en y_valid:\", np.unique(y_valid))\n",
    "\n",
    "present_classes = np.unique(y_valid)\n",
    "weights_partial = compute_class_weight(\n",
    "\tclass_weight=\"balanced\",\n",
    "\tclasses=present_classes,\n",
    "\ty=y_valid\n",
    ")\n",
    "\n",
    "full_weights = np.zeros(n_classes, dtype=np.float32)\n",
    "for c, w in zip(present_classes, weights_partial):\n",
    "\tfull_weights[int(c)] = float(w)\n",
    "\n",
    "class_weights = torch.tensor(full_weights, dtype=torch.float32).to(DEVICE)\n",
    "print(\"Pesos por clase (0..4):\", class_weights.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f7b3f1",
   "metadata": {},
   "source": [
    "## **6. Augmentaciones para TimeCLR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faafddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGTimeAugment:\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tseries_len: int = 128,\n",
    "\t\tp_jitter: float = 0.7,\t\tjitter_sigma: float = 0.01,   # ruido leve\n",
    "\t\tp_scaling: float = 0.6,\t\tscaling_sigma: float = 0.07,  # ganancia leve\n",
    "\t\tp_tmask: float = 0.4,\t\ttmask_frac=(0.03, 0.08),      # cutout corto\n",
    "\t\tp_crop: float = 0.6,\t\tcrop_frac=(0.7, 0.95),        # recorte moderado\n",
    "\t\tuse_perm: bool = False\n",
    "\t):\n",
    "\t\tself.T = series_len\n",
    "\t\tself.p_jitter = p_jitter; self.jitter_sigma = jitter_sigma\n",
    "\t\tself.p_scaling = p_scaling; self.scaling_sigma = scaling_sigma\n",
    "\t\tself.p_tmask = p_tmask; self.tmask_frac = tmask_frac\n",
    "\t\tself.p_crop = p_crop; self.crop_frac = crop_frac\n",
    "\t\tself.use_perm = use_perm\n",
    "\n",
    "\tdef _jitter(self, x):\n",
    "\t\ty = x + np.random.normal(0.0, self.jitter_sigma, size=x.shape)\n",
    "\t\treturn y.astype(x.dtype, copy=False)\n",
    "\n",
    "\tdef _scaling(self, x):\n",
    "\t\ty = x * np.random.normal(1.0, self.scaling_sigma)\n",
    "\t\treturn y.astype(x.dtype, copy=False)\n",
    "\n",
    "\tdef _time_mask(self, x):\n",
    "\t\ty = x.astype(np.float32, copy=False).copy()\n",
    "\t\tw = max(1, int(self.T * np.random.uniform(*self.tmask_frac)))\n",
    "\t\ts = np.random.randint(0, max(1, self.T - w + 1))\n",
    "\t\ty[s:s+w] = 0.0\n",
    "\t\treturn y.astype(x.dtype, copy=False)\n",
    "\n",
    "\tdef _crop(self, x):\n",
    "\t\tw = max(2, int(self.T * np.random.uniform(*self.crop_frac)))\n",
    "\t\ts = np.random.randint(0, max(1, self.T - w + 1))\n",
    "\t\tseg = x[s:s+w]\n",
    "\t\ti_old = np.linspace(0, 1, num=w)\n",
    "\t\ti_new = np.linspace(0, 1, num=self.T)\n",
    "\t\ty = np.interp(i_new, i_old, seg)   # -> float64\n",
    "\t\treturn y.astype(x.dtype, copy=False)\n",
    "\n",
    "\tdef __call__(self, x):\n",
    "\t\ty = x\n",
    "\t\tif np.random.rand() < self.p_crop:\n",
    "\t\t\ty = self._crop(y)\n",
    "\t\tif np.random.rand() < self.p_tmask:\n",
    "\t\t\ty = self._time_mask(y)\n",
    "\t\tif np.random.rand() < self.p_scaling:\n",
    "\t\t\ty = self._scaling(y)\n",
    "\t\tif np.random.rand() < self.p_jitter:\n",
    "\t\t\ty = self._jitter(y)\n",
    "\t\treturn y\n",
    "\t\n",
    "ecgtime_augment = ECGTimeAugment(series_len=SIGNALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3aab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ecgtime_augment(X_train[1])\n",
    "plot_ecg(X=aug, y=y_train[1], aug=True, aug_title=\"Augmentación\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd149af",
   "metadata": {},
   "source": [
    "## **7. Dataset para TimeCLR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa72d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeCLRDataset(Dataset):\n",
    "\tdef __init__(self, X, transform=None, eps=1e-6):\n",
    "\t\tX = np.asarray(X, dtype=np.float32)\n",
    "\t\tif X.ndim == 2:\n",
    "\t\t\tself.X = X\n",
    "\t\telif X.ndim == 3 and X.shape[1] == 1:\n",
    "\t\t\tself.X = X[:, 0, :]\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(\"X debe ser (N, T) o (N, 1, T)\")\n",
    "\t\tself.T = self.X.shape[1]\n",
    "\t\tself.transform = transform\n",
    "\t\tself.eps = eps\n",
    "\n",
    "\tdef __len__(self): return self.X.shape[0]\n",
    "\n",
    "\tdef _z(self, x):\n",
    "\t\tm, s = x.mean(), x.std()\n",
    "\t\treturn (x - m) / (s + self.eps)\n",
    "\n",
    "\tdef __getitem__(self, idx: int):\n",
    "\t\tx = self.X[idx]\n",
    "\t\ta1 = self.transform(x) if self.transform else x\n",
    "\t\ta2 = self.transform(x) if self.transform else x\n",
    "\n",
    "\t\t# Normaliza y fuerza float32\n",
    "\t\ta1 = self._z(a1).astype(np.float32, copy=False)\n",
    "\t\ta2 = self._z(a2).astype(np.float32, copy=False)\n",
    "\n",
    "\t\tx1 = torch.from_numpy(a1).unsqueeze(0)\n",
    "\t\tx2 = torch.from_numpy(a2).unsqueeze(0)\n",
    "\t\treturn x1, x2\n",
    "\n",
    "class LabeledECGDataset(Dataset):\n",
    "\tdef __init__(self, X, y, eps=1e-6):\n",
    "\t\tself.X = np.asarray(X, dtype=np.float32)\n",
    "\t\tself.y = np.asarray(y, dtype=np.int64)\n",
    "\t\tself.eps = eps\n",
    "\n",
    "\tdef __len__(self): return self.X.shape[0]\n",
    "\n",
    "\tdef _z(self, x):\n",
    "\t\tm, s = x.mean(), x.std()\n",
    "\t\treturn (x - m) / (s + 1e-6)\n",
    "\n",
    "\tdef __getitem__(self, i):\n",
    "\t\tx = torch.from_numpy(self._z(self.X[i])).unsqueeze(0)\n",
    "\t\ty = torch.tensor(self.y[i])\n",
    "\t\treturn x, y\n",
    "\n",
    "class UnlabeledECGDataset(Dataset):\n",
    "\tdef __init__(self, X, eps=1e-6):\n",
    "\t\tself.X = np.asarray(X, dtype=np.float32)\n",
    "\t\tself.eps = eps\n",
    "\n",
    "\tdef __len__(self): return self.X.shape[0]\n",
    "\n",
    "\tdef _z(self, x):\n",
    "\t\tm, s = x.mean(), x.std()\n",
    "\t\treturn (x - m) / (s + 1e-6)\n",
    "\n",
    "\tdef __getitem__(self, i):\n",
    "\t\tx = torch.from_numpy(self._z(self.X[i])).unsqueeze(0)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2821a643",
   "metadata": {},
   "source": [
    "## **8. Backbone de TimeCLR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc61245",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1DBackbone(nn.Module):\n",
    "\tdef __init__(self, in_ch: int = 1, emb_dim: int = 256):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.feat = nn.Sequential(\n",
    "\t\t\tnn.Conv1d(in_ch, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "\t\t\tnn.BatchNorm1d(64),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\n",
    "\t\t\tnn.Conv1d(64, 128, kernel_size=5, stride=2, padding=2, bias=False),\n",
    "\t\t\tnn.BatchNorm1d(128),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\n",
    "\t\t\tnn.Conv1d(128, 256, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "\t\t\tnn.BatchNorm1d(256),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\n",
    "\t\t\tnn.AdaptiveAvgPool1d(1)\n",
    "\t\t)\n",
    "\t\tself.fc = nn.Linear(256, emb_dim)\n",
    "\n",
    "\tdef forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\t\th = self.feat(x).squeeze(-1)\n",
    "\t\tz = self.fc(h)\n",
    "\t\treturn z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8dad49",
   "metadata": {},
   "source": [
    "## **9. ProjectionHead de TimeCLR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a866fd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionHead(nn.Module):\n",
    "\tdef __init__(self, in_dim: int, hid_dim: int = 256, out_dim: int = 128):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.net = nn.Sequential(\n",
    "\t\t\tnn.Linear(in_dim, hid_dim, bias=False),\n",
    "\t\t\tnn.BatchNorm1d(hid_dim),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.Linear(hid_dim, out_dim, bias=True)\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\t\treturn self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279ad9e3",
   "metadata": {},
   "source": [
    "## **10. LossFunction para TimeCLR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa22eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nt_xent_loss(z1: torch.Tensor, z2: torch.Tensor, temperature: float = 0.2) -> torch.Tensor:\n",
    "\t# Normaliza\n",
    "\tz1 = F.normalize(z1, dim=1)\n",
    "\tz2 = F.normalize(z2, dim=1)\n",
    "\n",
    "\tB = z1.size(0)\n",
    "\n",
    "\tZ = torch.cat([z1, z2], dim=0)\n",
    "\n",
    "\tif Z.dtype in (torch.float16, torch.bfloat16):\n",
    "\t\tZm = Z.float()\n",
    "\telse:\n",
    "\t\tZm = Z\n",
    "\n",
    "\tsim = torch.matmul(Zm, Zm.t()) / temperature\n",
    "\n",
    "\tmask = torch.eye(2 * B, dtype=torch.bool, device=Z.device)\n",
    "\tsim = sim.masked_fill(mask, float('-inf'))\n",
    "\n",
    "\ttarget = torch.cat([\n",
    "\t\ttorch.arange(B, 2 * B, device=Z.device),\n",
    "\t\ttorch.arange(0, B, device=Z.device)\n",
    "\t], dim=0)\n",
    "\n",
    "\tloss = F.cross_entropy(sim, target)\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d947328",
   "metadata": {},
   "source": [
    "## **11. Modelo de TimeCLR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088f256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeCLRModel(pl.LightningModule):\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\temb_dim: int = EMBEDDING_DIM,\n",
    "\t\tproj_hid: int = PROJ_HID,\n",
    "\t\tproj_out: int = PROJ_OUT,\n",
    "\t\ttemperature: float = TEMP,\n",
    "\t\tlr: float = LR_SSL,\n",
    "\t\tweight_decay: float = WD\n",
    "\t):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.save_hyperparameters()\n",
    "\t\tself.encoder = CNN1DBackbone(in_ch=1, emb_dim=emb_dim)\n",
    "\t\tself.projector = ProjectionHead(emb_dim, proj_hid, proj_out)\n",
    "\t\tself.temperature = temperature\n",
    "\t\tself.lr = lr\n",
    "\t\tself.weight_decay = weight_decay\n",
    "\n",
    "\tdef forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\t\th = self.encoder(x)\n",
    "\t\tz = self.projector(h)\n",
    "\t\treturn z\n",
    "\n",
    "\tdef training_step(self, batch, batch_idx):\n",
    "\t\tx1, x2 = batch\n",
    "\t\tz1 = self(x1)\n",
    "\t\tz2 = self(x2)\n",
    "\t\tloss = nt_xent_loss(z1, z2, self.temperature)\n",
    "\t\tself.log(\"train_loss\", loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "\t\treturn loss\n",
    "\n",
    "\tdef configure_optimizers(self):\n",
    "\t\topt = torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "\n",
    "\t\tsteps_per_epoch = len(self.trainer.datamodule.train_dataloader()) if self.trainer.datamodule else len(self.trainer.fit_loop._data_source.dataloader())\n",
    "\t\ttotal_steps = self.trainer.max_epochs * steps_per_epoch\n",
    "\t\twarmup_steps = int(0.1 * total_steps)\n",
    "\n",
    "\t\tdef warmup_then_cosine(step):\n",
    "\t\t\tif step < warmup_steps:\n",
    "\t\t\t\treturn step / max(1, warmup_steps)\n",
    "\t\t\tprogress = (step - warmup_steps) / max(1, total_steps - warmup_steps)\n",
    "\t\t\treturn 0.5 * (1 + math.cos(math.pi * progress))\n",
    "\n",
    "\t\tscheduler = LambdaLR(opt, lr_lambda=warmup_then_cosine)\n",
    "\n",
    "\t\treturn {\"optimizer\": opt, \"lr_scheduler\": {\"scheduler\": scheduler, \"interval\": \"step\"}}\n",
    "\n",
    "\t@torch.no_grad()\n",
    "\tdef encode(self, x: torch.Tensor, normalize: bool = True) -> torch.Tensor:\n",
    "\t\th = self.encoder(x)\n",
    "\t\tif normalize:\n",
    "\t\t\th = F.normalize(h, dim=1)\n",
    "\t\treturn h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efcac8b",
   "metadata": {},
   "source": [
    "## **12. Pre-Entrenamiento SimCLR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dcddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_train = X_train\n",
    "ssl_ds = TimeCLRDataset(\n",
    "\tX=X_all_train,\n",
    "\ttransform=ecgtime_augment\n",
    ")\n",
    "ssl_dl = DataLoader(\n",
    "\tssl_ds,\n",
    "\tbatch_size=BATCH_SSL,\n",
    "\tshuffle=True,\n",
    "\tnum_workers=NUM_WORKERS,\n",
    "\tpin_memory=True\n",
    ")\n",
    "\n",
    "timeclr_model = TimeCLRModel(\n",
    "\temb_dim=EMBEDDING_DIM,\n",
    "\tproj_hid=PROJ_HID,\n",
    "\tproj_out=PROJ_OUT,\n",
    "\ttemperature=TEMP,\n",
    "\tlr=LR_SSL,\n",
    "\tweight_decay=WD\n",
    ")\n",
    "\n",
    "steps_per_epoch = max(1, len(ssl_dl))\n",
    "warmup_steps = int(0.1 * EPOCHS_SSL * steps_per_epoch)\n",
    "lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval=\"step\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "\tmax_epochs=EPOCHS_SSL,\n",
    "\taccelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "\tdevices=1,\n",
    "\tprecision=\"16-mixed\" if torch.cuda.is_available() else 32,\n",
    "\tbenchmark=True,\n",
    "\tlog_every_n_steps=10,\n",
    "\tgradient_clip_val=1.0,\n",
    "\tcallbacks=[lr_monitor]\n",
    ")\n",
    "trainer.fit(timeclr_model, ssl_dl)\n",
    "\n",
    "encoder = timeclr_model.encoder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afb9ff3",
   "metadata": {},
   "source": [
    "## **13. LinearProbe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1effafd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = LabeledECGDataset(X_lab_train, y_lab_train)\n",
    "test_ds  = LabeledECGDataset(X_test, y_test.astype(int))\n",
    "\n",
    "train_dl = DataLoader(\n",
    "\ttrain_ds,\n",
    "\tbatch_size=BATCH_LP,\n",
    "\tshuffle=True,\n",
    "\tnum_workers=NUM_WORKERS\n",
    ")\n",
    "test_dl = DataLoader(\n",
    "\ttest_ds,\n",
    "\tbatch_size=BATCH_LP,\n",
    "\tshuffle=False,\n",
    "\tnum_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "class LinearProbe(pl.LightningModule):\n",
    "\tdef __init__(self, encoder, n_classes: int, lr: float = LR_LP, wd: float = WD):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.encoder = encoder\n",
    "\t\tfor p in self.encoder.parameters():\n",
    "\t\t\tp.requires_grad = False\n",
    "\t\tself.head = nn.Linear(256, n_classes)\n",
    "\t\tself.lr, self.wd = lr, wd\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\th = self.encoder(x)\n",
    "\t\treturn self.head(h)\n",
    "\n",
    "\tdef training_step(self, batch, _):\n",
    "\t\tx, y = batch\n",
    "\t\tlogits = self(x)\n",
    "\t\tloss = F.cross_entropy(logits, y, weight=class_weights)\n",
    "\t\tself.log(\"lp_train_loss\", loss, prog_bar=True)\n",
    "\t\treturn loss\n",
    "\n",
    "\tdef test_step(self, batch, _):\n",
    "\t\tx, y = batch\n",
    "\t\tlogits = self(x)\n",
    "\t\tpred = logits.argmax(1)\n",
    "\t\tacc = (pred == y).float().mean()\n",
    "\t\tself.log(\"lp_test_acc\", acc, prog_bar=True)\n",
    "\n",
    "\tdef configure_optimizers(self):\n",
    "\t\treturn torch.optim.AdamW(self.head.parameters(), lr=self.lr, weight_decay=self.wd)\n",
    "\n",
    "lp = LinearProbe(\n",
    "\tencoder,\n",
    "\tn_classes=num_classes,\n",
    "\tlr=LR_LP, \n",
    "\twd=WD\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "\tmax_epochs=EPOCHS_LP,\n",
    "\taccelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "\tdevices=1\n",
    ")\n",
    "trainer.fit(lp, train_dl)\n",
    "trainer.test(lp, test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957dc00e",
   "metadata": {},
   "source": [
    "## **14. FineTuning TimeCLR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f56566",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTune(pl.LightningModule):\n",
    "\tdef __init__(self, encoder, n_classes: int, lr_enc=LR_FT_ENC, lr_head=LR_FT_HEAD, wd=WD):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.encoder = encoder\n",
    "\t\tself.head = nn.Linear(256, n_classes)\n",
    "\t\tself.lr_enc, self.lr_head, self.wd = lr_enc, lr_head, wd\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\th = self.encoder(x)\n",
    "\t\treturn self.head(h)\n",
    "\n",
    "\tdef training_step(self, batch, _):\n",
    "\t\tx, y = batch\n",
    "\t\tlogits = self(x)\n",
    "\t\tloss = F.cross_entropy(logits, y, weight=class_weights)\n",
    "\t\tself.log(\"ft_train_loss\", loss, prog_bar=True)\n",
    "\t\treturn loss\n",
    "\n",
    "\tdef validation_step(self, batch, _):\n",
    "\t\tx, y = batch\n",
    "\t\tlogits = self(x)\n",
    "\t\tpred = logits.argmax(1)\n",
    "\t\tacc = (pred == y).float().mean()\n",
    "\t\tself.log(\"ft_val_acc\", acc, prog_bar=True)\n",
    "\n",
    "\tdef test_step(self, batch, _):\n",
    "\t\tx, y = batch\n",
    "\t\tlogits = self(x)\n",
    "\t\tpred = logits.argmax(1)\n",
    "\t\tacc = (pred == y).float().mean()\n",
    "\t\tself.log(\"ft_test_acc\", acc, prog_bar=True)\n",
    "\n",
    "\tdef configure_optimizers(self):\n",
    "\t\tparams = [\n",
    "\t\t\t{\"params\": self.encoder.parameters(), \"lr\": self.lr_enc, \"weight_decay\": self.wd},\n",
    "\t\t\t{\"params\": self.head.parameters(),    \"lr\": self.lr_head, \"weight_decay\": self.wd},\n",
    "\t\t]\n",
    "\t\topt = torch.optim.AdamW(params)\n",
    "\t\tsch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS_FT)\n",
    "\t\treturn {\"optimizer\": opt, \"lr_scheduler\": sch}\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_lab_train, y_lab_train, test_size=0.2, stratify=y_lab_train, random_state=42)\n",
    "\n",
    "dl_tr = DataLoader(\n",
    "\tLabeledECGDataset(X_tr, y_tr),\n",
    "\tbatch_size=BATCH_FT,\n",
    "\tshuffle=True,\n",
    "\tnum_workers=NUM_WORKERS\n",
    ")\n",
    "dl_val = DataLoader(\n",
    "\tLabeledECGDataset(X_val, y_val),\n",
    "\tbatch_size=BATCH_FT,\n",
    "\tshuffle=False,\n",
    "\tnum_workers=NUM_WORKERS\n",
    ")\n",
    "dl_te = DataLoader(\n",
    "\ttest_ds,\n",
    "\tbatch_size=BATCH_FT,\n",
    "\tshuffle=False,\n",
    "\tnum_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "early_stop = pl.callbacks.EarlyStopping(monitor=\"ft_val_acc\", mode=\"max\", patience=10)\n",
    "ckpt = pl.callbacks.ModelCheckpoint(monitor=\"ft_val_acc\", mode=\"max\", save_top_k=1)\n",
    "\n",
    "ft = FineTune(encoder, n_classes=num_classes)\n",
    "trainer = pl.Trainer(\n",
    "\tmax_epochs=EPOCHS_FT,\n",
    "\taccelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "\tdevices=1,\n",
    "\tcallbacks=[early_stop, ckpt]\n",
    ")\n",
    "trainer.fit(ft, dl_tr, dl_val)\n",
    "trainer.test(ft, dl_te)\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb4745b",
   "metadata": {},
   "source": [
    "## **15. Evaluación del Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ba8627",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_all_metrics(\n",
    "\tmodel: torch.nn.Module,\n",
    "\tdataloader,\n",
    "\tnum_classes: int,\n",
    "\tclass_names: Optional[List[str]] = None,\n",
    "\tdevice: Optional[torch.device] = None,\n",
    "\tnormalize_cm: bool = True\n",
    ") -> Dict[str, object]:\n",
    "\tmodel.eval()\n",
    "\tif device is None:\n",
    "\t\tdevice = next(model.parameters()).device\n",
    "\n",
    "\tall_preds = []\n",
    "\tall_probs = []\n",
    "\tall_true  = []\n",
    "\n",
    "\tfor batch in dataloader:\n",
    "\t\tif isinstance(batch, (list, tuple)) and len(batch) == 2:\n",
    "\t\t\tx, y = batch\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(\"Dataloader debe entregar (x, y).\")\n",
    "\n",
    "\t\tx = x.to(device)\n",
    "\t\ty = y.to(device)\n",
    "\n",
    "\t\tlogits = model(x)\n",
    "\t\tprobs  = F.softmax(logits, dim=1)\n",
    "\t\tpreds  = probs.argmax(1)\n",
    "\n",
    "\t\tall_true.append(y.cpu().numpy())\n",
    "\t\tall_preds.append(preds.cpu().numpy())\n",
    "\t\tall_probs.append(probs.cpu().numpy())\n",
    "\n",
    "\ty_true = np.concatenate(all_true, axis=0)\n",
    "\ty_pred = np.concatenate(all_preds, axis=0)\n",
    "\ty_prob = np.concatenate(all_probs, axis=0)\n",
    "\n",
    "\tacc     = accuracy_score(y_true, y_pred)\n",
    "\tf1_mac  = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "\trec_per_class = recall_score(y_true, y_pred, average=None, labels=np.arange(num_classes), zero_division=0)\n",
    "\n",
    "\ttarget_names = class_names if (class_names is not None and len(class_names) == num_classes) else None\n",
    "\tcls_report = classification_report(\n",
    "\t\ty_true, y_pred,\n",
    "\t\ttarget_names=target_names,\n",
    "\t\tzero_division=0,\n",
    "\t\tdigits=4\n",
    "\t)\n",
    "\n",
    "\tcm = confusion_matrix(y_true, y_pred, labels=np.arange(num_classes))\n",
    "\tif normalize_cm:\n",
    "\t\twith np.errstate(all=\"ignore\"):\n",
    "\t\t\tcm_norm = cm / cm.sum(axis=1, keepdims=True)\n",
    "\t\t\tcm_norm = np.nan_to_num(cm_norm)\n",
    "\telse:\n",
    "\t\tcm_norm = None\n",
    "\n",
    "\troc_auc_macro = None\n",
    "\ttry:\n",
    "\t\tunique_test_classes = np.unique(y_true)\n",
    "\t\tif num_classes == 2:\n",
    "\t\t\tif set(unique_test_classes.tolist()) == {0, 1}:\n",
    "\t\t\t\troc_auc_macro = roc_auc_score(y_true, y_prob[:, 1])\n",
    "\t\t\telse:\n",
    "\t\t\t\tclasses_sorted = np.sort(unique_test_classes)\n",
    "\t\t\t\tmapper = {c:i for i, c in enumerate(classes_sorted)}\n",
    "\t\t\t\ty_true_bin = np.vectorize(mapper.get)(y_true)\n",
    "\t\t\t\tpos_index = np.where(classes_sorted == classes_sorted.max())[0][0]\n",
    "\t\t\t\troc_auc_macro = roc_auc_score(y_true_bin, y_prob[:, pos_index])\n",
    "\t\telse:\n",
    "\t\t\tif len(unique_test_classes) >= 2:\n",
    "\t\t\t\troc_auc_macro = roc_auc_score(y_true, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "\t\t\telse:\n",
    "\t\t\t\troc_auc_macro = None\n",
    "\texcept Exception as e:\n",
    "\t\troc_auc_macro = None\n",
    "\n",
    "\tresults = {\n",
    "\t\t\"f1_macro\": f1_mac,\n",
    "\t\t\"accuracy\": acc,\n",
    "\t\t\"recall_per_class\": rec_per_class,\n",
    "\t\t\"confusion_matrix\": cm,\n",
    "\t\t\"confusion_matrix_normalized\": cm_norm,\n",
    "\t\t\"roc_auc_macro\": roc_auc_macro,\n",
    "\t\t\"classification_report\": cls_report,\n",
    "\t}\n",
    "\n",
    "\t# Impresión amigable\n",
    "\tprint(\"\\n=== Evaluación ===\")\n",
    "\tprint(f\"F1-macro: {f1_mac:.4f}\")\n",
    "\tprint(f\"Accuracy: {acc:.4f}\")\n",
    "\tif roc_auc_macro is not None:\n",
    "\t\tprint(f\"ROC-AUC macro (OVR): {roc_auc_macro:.4f}\")\n",
    "\telse:\n",
    "\t\tprint(\"ROC-AUC macro: no disponible (clases ausentes o caso no válido).\")\n",
    "\n",
    "\tprint(\"\\nRecall por clase:\")\n",
    "\tif target_names is not None:\n",
    "\t\tfor i, r in enumerate(rec_per_class):\n",
    "\t\t\tprint(f\"  {target_names[i]}: {r:.4f}\")\n",
    "\telse:\n",
    "\t\tfor i, r in enumerate(rec_per_class):\n",
    "\t\t\tprint(f\"  clase {i}: {r:.4f}\")\n",
    "\n",
    "\tprint(\"\\nReporte por clase:\\n\", cls_report)\n",
    "\tprint(\"Matriz de confusión (cruda):\\n\", cm)\n",
    "\tif cm_norm is not None:\n",
    "\t\tprint(\"Matriz de confusión (normalizada por fila):\\n\", np.round(cm_norm, 4))\n",
    "\n",
    "\treturn results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2211a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = int(np.unique(y_train[~np.isnan(y_train).astype(bool)]).size) if hasattr(y_train, \"dtype\") else int(np.unique(y_train).size)\n",
    "\n",
    "class_names = [\n",
    "\t\"(N) Latido normal\",\n",
    "\t\"(S) Latido supraventricular\",\n",
    "\t\"(V) Latido ventricular ectópico\",\n",
    "\t\"(F) Latido de fusión\",\n",
    "\t\"(Q) Latido desconocido\"\n",
    "]\n",
    "\n",
    "results = evaluate_all_metrics(\n",
    "\tmodel=ft,\n",
    "\tdataloader=test_dl,\n",
    "\tnum_classes=num_classes,\n",
    "\tclass_names=class_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c312e7",
   "metadata": {},
   "source": [
    "## **16 Escritura del CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0366a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def write_predictions_csv(model, test_dl, out_path=\"preds.csv\"):\n",
    "\tmodel.eval()\n",
    "\tdevice = next(model.parameters()).device\n",
    "\n",
    "\tids = []\n",
    "\tpreds = []\n",
    "\trunning_id = 0\n",
    "\n",
    "\tfor batch in test_dl:\n",
    "\t\tif isinstance(batch, (list, tuple)) and len(batch) >= 1:\n",
    "\t\t\tx = batch[0]\n",
    "\t\telse:\n",
    "\t\t\tx = batch\n",
    "\n",
    "\t\tbsz = x.size(0)\n",
    "\t\tx = x.to(device)\n",
    "\n",
    "\t\tlogits = model(x)\n",
    "\t\tp = F.softmax(logits, dim=1)\n",
    "\t\tyhat = p.argmax(1).cpu().numpy()\n",
    "\n",
    "\t\tids.extend(range(running_id, running_id + bsz))\n",
    "\t\tpreds.extend(yhat.tolist())\n",
    "\t\trunning_id += bsz\n",
    "\n",
    "\tdf = pd.DataFrame({\"ID\": ids, \"label\": preds})\n",
    "\tdf.to_csv(out_path, index=False)\n",
    "\tprint(f\"CSV de predicciones guardado en: {out_path}\")\n",
    "\n",
    "write_predictions_csv(\n",
    "\tft,\n",
    "\ttest_dl,\n",
    "\tout_path=f\"timeclr_predictions_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.csv\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
