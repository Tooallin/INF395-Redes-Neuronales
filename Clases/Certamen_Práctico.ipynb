{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKJFt7YxH8yl"
      },
      "source": [
        "# Introducción a las Redes Neuronales INF-395 II-2025\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Nombre: Alessandro Bruno Cintolesi Rodríguez\n",
        "* ROL: 202173541-0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSrUPgapO0tf"
      },
      "outputs": [],
      "source": [
        "# Import torch\n",
        "import torch\n",
        "\n",
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n",
        "\n",
        "# Setup random seed\n",
        "RANDOM_SEED = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH7jIZ2SPFee"
      },
      "source": [
        "## 1. Cree un conjunto de datos de clasificación binaria con Scikit-Learn [`make_moons()`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html) function.\n",
        "* Para mantener la coherencia, el conjunto de datos debe tener 1000 muestras y un `random_state=42`.\n",
        "* Convierte los datos en tensores de PyTorch.\n",
        "* Divida los datos en conjuntos de entrenamiento y prueba utilizando `train_test_split` con 80 % de entrenamiento y 20 % de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5t4VhPV1PX1X"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_moons\n",
        "\n",
        "n_samples=1000\n",
        "X, y = make_moons(n_samples, random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUeHZ3-3P9C7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "moons = pd.DataFrame({\"X1\": X[:, 0], \"X2\": X[:, 1], \"label\": y })\n",
        "moons.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owrkPSFvQPFI"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "moons['X1'].plot(kind='hist', bins=20, title='X1')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "moons.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.scatter(x=X[:, 0], y=X[:, 1],  c=y, cmap=plt.cm.RdYlBu);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = torch.from_numpy(X).type(torch.float)\n",
        "y = torch.from_numpy(y).type(torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDhyHn9fR4dq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMIjxZdzQfPz"
      },
      "source": [
        "## 2. Construya un modelo subclasificando `nn.Module` que incorpore funciones de activación no lineal y sea capaz de ajustar los datos que creó en 1.\n",
        "* Siéntase libre de utilizar cualquier combinación de capas (lineales y no lineales) que desees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwtyvm34Ri6Q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class MoonModelV0(nn.Module):\n",
        "\t## Your code here ##\n",
        "\tdef __init__(self, in_features=2, hidden=32, out_features=1):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.layer_1 = nn.Linear(in_features, hidden)\n",
        "\t\tself.layer_2 = nn.Linear(hidden, hidden)\n",
        "\t\tself.layer_3 = nn.Linear(hidden, hidden)\n",
        "\t\tself.layer_4 = nn.Linear(hidden, hidden)\n",
        "\t\tself.layer_5 = nn.Linear(hidden, hidden)\n",
        "\t\tself.layer_6 = nn.Linear(hidden, out_features)\n",
        "\t\tself.relu = nn.ReLU()\n",
        "\t\tself.tanh = nn.Tanh()\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tx = self.relu(self.layer_1(x))\n",
        "\t\tx = self.tanh(self.layer_2(x))\n",
        "\t\tx = self.relu(self.layer_3(x))\n",
        "\t\tx = self.tanh(self.layer_4(x))\n",
        "\t\tx = self.relu(self.layer_5(x))\n",
        "\t\treturn self.layer_6(x)\n",
        "\n",
        "# Instantiate the model\n",
        "## Your code here ##\n",
        "moon_model = MoonModelV0(in_features=2, hidden=32, out_features=1).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSj97RwyVeFE"
      },
      "source": [
        "\n",
        "## 3. Configurar una función de pérdida compatible con clasificación binaria y un optimizador para usar al entrenar el modelo integrado en 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whSGw5qgVvxU"
      },
      "outputs": [],
      "source": [
        "# Setup loss function\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Setup optimizer to optimize model's parameters\n",
        "optimizer = torch.optim.SGD(moon_model.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvk4PfNTWUAt"
      },
      "source": [
        "## 4. Cree un bucle de entrenamiento y prueba para ajustar el modelo que creó en 2 a los datos que creó en 1.\n",
        "*  Realice un análisis de avance del modelo para ver los resultados en forma de logits, probabilidades de predicción y etiquetas.\n",
        "* Para medir la precisión del modelo, puede crear su propia función de precisión o usar la función de precisión de [TorchMetrics](https://torchmetrics.readthedocs.io/en/latest/).\n",
        "* Entrene el modelo durante el tiempo suficiente para que alcance un accuracy superior al 96.\n",
        "* El bucle de entrenamiento debe mostrar el progreso cada 10 épocas de la pérdida y la precisión de los conjuntos de entrenamiento y prueba del modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgnFdlamd2-D",
        "outputId": "fbf5dead-552d-44da-8136-ad72741c188e"
      },
      "outputs": [],
      "source": [
        "#¿Qué sale de nuestro modelo?\n",
        "\n",
        "# logits\n",
        "print(\"Logits: Es el valor crudo que nos entrega nuestro modelo al predecir un input, este aun no corresponde a una probabilidad hasta que se le haya sido aplicada la funcion de activacion sigmoide\")\n",
        "\n",
        "# Predicción probabilidades\n",
        "print(\"Pred probs: Corresponde a la distribución de probabilidades que predice nuestro modelo respecto a las distintas etiquetas en nuestro problema, en este caso en particular 2.\")\n",
        "\n",
        "# Predicción etiquetas\n",
        "print(\"Pred etiquetas: Correspondera a la etiqueta a la cual nuestro modelo predice que pertenece un determinado input.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUSDNHB4euoJ",
        "outputId": "9b785b94-f30a-43e8-de6f-6ee3430a2286"
      },
      "outputs": [],
      "source": [
        "!pip -q install torchmetrics\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "## TODO: Descomente este código para utilizar la función Accuracy\n",
        "acc_fn = Accuracy(task=\"multiclass\", num_classes=2).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHBY3h7XXnxt"
      },
      "outputs": [],
      "source": [
        "## TODO: Descomente esto para establecer la semilla\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "# Configure epochs\n",
        "epochs = 1000\n",
        "\n",
        "# Enviar datos al dispositivo\n",
        "X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "# Recorrer los datos\n",
        "for epoch in range(epochs):\n",
        "\t### Entrenamiento\n",
        "\n",
        "\t# 1. Forward pass\n",
        "\ty_logits = moon_model(X_train).squeeze()\n",
        "\n",
        "\t# Convierte los logits en probabilidades de predicción\n",
        "\ty_prob = torch.sigmoid(y_logits)\n",
        "\n",
        "\t# Convierte las probabilidades de predicción en etiquetas de predicción\n",
        "\ty_pred = torch.round(y_prob)\n",
        "\n",
        "\t# 2. Calcule la loss\n",
        "\ttrain_loss = loss_fn(y_logits, y_train)\n",
        "\n",
        "\t# Calcule  accuracy\n",
        "\ttrain_acc = acc_fn(y_pred, y_train.int())\n",
        "\n",
        "\t# 3.  gradients\n",
        "\toptimizer.zero_grad()\n",
        "\n",
        "\t# 4. Loss backward (backpropagation)\n",
        "\ttrain_loss.backward()\n",
        "\n",
        "\t# 5. optimizer (gradient descent)\n",
        "\toptimizer.step()\n",
        "\n",
        "\t### Testing\n",
        "\tmoon_model.eval()\n",
        "\twith torch.inference_mode():\n",
        "\t\t# 1. Forward pass (to get the logits)\n",
        "\t\ttest_logits = moon_model(X_test).squeeze()\n",
        "\n",
        "\t\t# Convierte las probabilidades de predicción en etiquetas de predicción\n",
        "\t\ttest_prob = torch.sigmoid(test_logits)\n",
        "\t\ttest_pred = torch.round(test_prob)\n",
        "\n",
        "\t\t# 2. Cacular el test loss/acc\n",
        "\t\ttest_loss = loss_fn(test_logits, y_test)\n",
        "\t\ttest_acc = acc_fn(test_pred, y_test.int())\n",
        "\n",
        "\t\t# Print lo que sucede cada 100 epochs\n",
        "\t\tif epoch % 100 == 0:\n",
        "\t\t\tprint(f\"Epoch: {epoch} | Train Loss: {train_loss:.5f}, Train Accuracy: {train_acc*100:.2f}% | Test Loss: {test_loss:.5f}, Test Accuracy: {test_acc*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Nwihtomj9JO"
      },
      "source": [
        "## 5. Make predictions with your trained model and plot them using the `plot_decision_boundary()` function created in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YRzatb8a1P2"
      },
      "outputs": [],
      "source": [
        "# Plot the model predictions\n",
        "import numpy as np\n",
        "\n",
        "def plot_decision_boundary(model, X, y):\n",
        "\n",
        "\n",
        "\tmodel.to(\"cpu\")\n",
        "\tX, y = X.to(\"cpu\"), y.to(\"cpu\")\n",
        "\n",
        "\t# Source - https://madewithml.com/courses/foundations/neural-networks/\n",
        "\t# (with modifications)\n",
        "\tx_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
        "\ty_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
        "\txx, yy = np.meshgrid(np.linspace(x_min, x_max, 101),\n",
        "\t\t\t\t\t\t np.linspace(y_min, y_max, 101))\n",
        "\n",
        "\t# Make features\n",
        "\tX_to_pred_on = torch.from_numpy(np.column_stack((xx.ravel(), yy.ravel()))).float()\n",
        "\n",
        "\t# Make predictions\n",
        "\tmodel.eval()\n",
        "\twith torch.inference_mode():\n",
        "\t\ty_logits = model(X_to_pred_on)\n",
        "\n",
        "\t# Test for multi-class or binary and adjust logits to prediction labels\n",
        "\tif len(torch.unique(y)) > 2:\n",
        "\t\ty_pred = torch.softmax(y_logits, dim=1).argmax(dim=1) # mutli-class\n",
        "\telse:\n",
        "\t\ty_pred = torch.round(torch.sigmoid(y_logits)) # binary\n",
        "\n",
        "\t# Reshape preds and plot\n",
        "\ty_pred = y_pred.reshape(xx.shape).detach().numpy()\n",
        "\tplt.contourf(xx, yy, y_pred, cmap=plt.cm.RdYlBu, alpha=0.7)\n",
        "\tplt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.RdYlBu)\n",
        "\tplt.xlim(xx.min(), xx.max())\n",
        "\tplt.ylim(yy.min(), yy.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMrcpyirig1d"
      },
      "outputs": [],
      "source": [
        "# Plot decision boundaries for training and test sets\n",
        "plot_decision_boundary(moon_model, X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_decision_boundary(moon_model, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lbt1bNcWk5G9"
      },
      "source": [
        "## 6. Cree un conjunto de datos de múltiples clases utilizando la función [spirals data creation function from CS231n](https://cs231n.github.io/neural-networks-case-study/) (see below for the code).\n",
        "* SDividir los datos en conjuntos de entrenamiento y prueba (80 % entrenamiento, 20 % prueba) y convertirlos en tensores de PyTorch.\n",
        "* Construya un modelo capaz de ajustar los datos (es posible que necesite una combinación de capas lineales y no lineales).\n",
        "* Construya una función de pérdida y un optimizador capaz de manejar datos de múltiples clases (extensión opcional: use el optimizador Adam en lugar de SGD, es posible que tenga que experimentar con diferentes valores de la tasa de aprendizaje para que funcione).\n",
        "* Realice un ciclo de entrenamiento y prueba para los datos de múltiples clases y entrene un modelo en él para alcanzar una precisión de prueba de más del 95 % (puede usar cualquier función de medición de precisión que desee aquí): 1000 épocas deberían ser suficientes.\n",
        "* Grafique los límites de decisión en el conjunto de datos de espirales a partir de las predicciones de su modelo; la función `plot_decision_boundary()` también debería funcionar para este conjunto de datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "tU-UNZsKlJls",
        "outputId": "e516317b-dc26-4e4a-dcbf-ae03b3b68b71"
      },
      "outputs": [],
      "source": [
        "# Code for creating a spiral dataset from CS231n\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "N = 100 # number of points per class\n",
        "D = 2 # dimensionality\n",
        "K = 3 # number of classes\n",
        "X = np.zeros((N*K,D)) # data matrix (each row = single example)\n",
        "y = np.zeros(N*K, dtype='uint8') # class labels\n",
        "for j in range(K):\n",
        "\tix = range(N*j,N*(j+1))\n",
        "\tr = np.linspace(0.0,1,N) # radius\n",
        "\tt = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*0.2 # theta\n",
        "\tX[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
        "\ty[ix] = j\n",
        "# lets visualize the data\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.RdYlBu)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWVrmkEyl0VP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "X = torch.from_numpy(X).type(torch.float)\n",
        "y = torch.from_numpy(y).type(torch.LongTensor)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
        "len(X_train), len(X_test), len(y_train), len(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-v-7f0op0tG"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip -q install torchmetrics\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "## TODO: uncomment the two lines below to send the accuracy function to the device\n",
        "acc_fn = Accuracy(task=\"multiclass\", num_classes=3).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DB3u3ldumapf"
      },
      "outputs": [],
      "source": [
        "#\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Create model by subclassing nn.Module\n",
        "class SpiralModelV0(nn.Module):\n",
        "\t## Your code here ##\n",
        "\tdef __init__(self, in_features=2, hidden=64, out_features=3):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.layer_1 = nn.Linear(in_features, hidden)\n",
        "\t\tself.layer_2 = nn.Linear(hidden, hidden)\n",
        "\t\tself.layer_3 = nn.Linear(hidden, hidden)\n",
        "\t\tself.layer_4 = nn.Linear(hidden, out_features)\n",
        "\t\tself.relu = nn.ReLU()\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tx = self.relu(self.layer_1(x))\n",
        "\t\tx = self.relu(self.layer_2(x))\n",
        "\t\tx = self.relu(self.layer_3(x))\n",
        "\t\treturn self.layer_4(x)\n",
        "\n",
        "# Instantiate model and send it to device\n",
        "spiral_model = SpiralModelV0(in_features=2, hidden=64, out_features=3).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE7XWSSunMTS",
        "outputId": "299400c0-1de4-419f-fdc9-055dabfc948b"
      },
      "outputs": [],
      "source": [
        "# Setup data to be device agnostic\n",
        "\n",
        "# Print out first 10 untrained model outputs (forward pass)\n",
        "print(\"Logits:\")\n",
        "## Your code here ##\n",
        "untrained_preds = spiral_model(X_test.to(device))\n",
        "print(f\"First 10 predictions logits:\\n{untrained_preds[:10]}\")\n",
        "\n",
        "print(\"\\nPred probs:\")\n",
        "## Your code here ##\n",
        "untrained_probs = torch.sigmoid(test_logits)\n",
        "print(f\"First 10 predictions probabilities:\\n{untrained_probs[:10]}\")\n",
        "\n",
        "print(\"\\nPred labels:\")\n",
        "## Your code here ##\n",
        "untrained_labels = torch.round(test_prob)\n",
        "print(f\"First 10 predictions labels:\\n{untrained_labels[:10]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54EqLRKLo0AW"
      },
      "outputs": [],
      "source": [
        "# Setup loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=spiral_model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIlExkUHnmxi"
      },
      "outputs": [],
      "source": [
        "# Build a training loop for the model\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "epochs = 1000\n",
        "\n",
        "X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "# Loop over data\n",
        "for epoch in range(epochs):\n",
        "    ## Training\n",
        "\n",
        "\t# 1. Forward pass\n",
        "\ttrain_logits = spiral_model(X_train)\n",
        "\n",
        "\t# 2. Calcula la loss\n",
        "\ttrain_loss = loss_fn(train_logits, y_train)\n",
        "\ttrain_acc = acc_fn(train_logits, y_train)\n",
        "\n",
        "\t# 3. Optimizador zero grad\n",
        "\toptimizer.zero_grad()\n",
        "\n",
        "\t# 4. Loss backward\n",
        "\ttrain_loss.backward()\n",
        "\n",
        "\t# 5. Optimizer step\n",
        "\toptimizer.step()\n",
        "\n",
        "\t## Testing\n",
        "\tspiral_model.eval()\n",
        "\twith torch.inference_mode():\n",
        "\t\t# 1. Forward pass\n",
        "\t\ttest_logits = spiral_model(X_test)\n",
        "\n",
        "\t\t# 2. Caculate loss and acc\n",
        "\t\ttest_loss = loss_fn(test_logits, y_test)\n",
        "\t\ttest_acc = acc_fn(test_logits, y_test)\n",
        "\n",
        "\t\t# Print out what's happening every 100 epochs\n",
        "\t\tif epoch % 100 == 0:\n",
        "\t\t\tprint(f\"Epoch: {epoch} | Train Loss: {train_loss:.5f}, Train Accuracy: {train_acc*100:.2f}% | Test Loss: {test_loss:.5f}, Test Accuracy: {test_acc*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrwVRbaE0keT"
      },
      "outputs": [],
      "source": [
        "# Plot decision boundaries for training and test sets\n",
        "plot_decision_boundary(spiral_model, X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot decision boundaries for training and test sets\n",
        "plot_decision_boundary(spiral_model, X_test, y_test)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
