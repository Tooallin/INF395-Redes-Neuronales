{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1710b8fa",
   "metadata": {},
   "source": [
    "# Análisis de Lesiones Cutáneas para la Detección de Melanoma\n",
    "## INF395 Introducción a las Redes Neuronales and Deep Learning\n",
    "- Estudiante: Alessandro Bruno Cintolesi Rodríguez\n",
    "- ROL: 202173541-0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f66386",
   "metadata": {},
   "source": [
    "## 1) Libraries and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f30e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Standard Library ===\n",
    "import os\t\t\t\t\t\t\t\t\t# Filesystem and environment utilities\n",
    "import re\t\t\t\t\t\t\t\t\t# Regular expressions\n",
    "import random\t\t\t\t\t\t\t\t# Random sampling and shuffling\n",
    "from pathlib import Path\t\t\t\t\t# Object-oriented filesystem paths\n",
    "from timeit import default_timer as timer\t# Benchmarking and timing\n",
    "\n",
    "# === Third-party (General / Utility) ===\n",
    "import numpy as np\t\t\t\t\t\t\t# Numerical computing\n",
    "import pandas as pd\t\t\t\t\t\t\t# Data manipulation\n",
    "import requests\t\t\t\t\t\t\t\t# HTTP requests\n",
    "from PIL import Image\t\t\t\t\t\t# Image loading and basic processing\n",
    "import matplotlib.pyplot as plt\t\t\t\t# Plotting and visualization\n",
    "\n",
    "# === PyTorch Core ===\n",
    "import torch\n",
    "from torch import nn\t\t\t\t\t\t# Neural network modules\n",
    "import torch.nn.functional as F\t\t\t\t# Functional API (activations, losses)\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "# === TorchVision ===\n",
    "from torchvision import datasets\t\t\t# Datasets like ImageFolder\n",
    "from torchvision import transforms\t\t\t# Image transformations\n",
    "from torchvision import models              # Models (ResNet-18)\n",
    "\n",
    "# === Scikit-learn Metrics & Utilities ===\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# === Progress & Logging ===\n",
    "from tqdm.auto import tqdm\t\t\t\t\t# Progress bar (notebook-friendly)\n",
    "\n",
    "# === Target class order expected by external evaluation (e.g., Kaggle submission) ===\n",
    "_TARGET_LABELS = [\"melanoma\", \"nevus\", \"seborrheic_keratosis\"]\n",
    "\n",
    "# === Set model variables ===\n",
    "MODEL_NAME = \"pretrained_resnet18\"\n",
    "NUM_EPOCHS = 30\n",
    "PRETRAINED_RESTNET18 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60100bb",
   "metadata": {},
   "source": [
    "## 2) Setting up random seed and device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea44ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(\"Using device:\", device)\n",
    "if device.type == \"cuda\":\n",
    "\tprint(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a1c7ab",
   "metadata": {},
   "source": [
    "## 3) Definition of recurrent functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250146b5",
   "metadata": {},
   "source": [
    "### 3.1) Function that prints the difference between the start time and the end time of the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a750ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "\t\"\"\"Prints difference between start and end time.\n",
    "\n",
    "\tArgs:\n",
    "\t\tstart (float): Start time of computation (preferred in timeit format).\n",
    "\t\tend (float): End time of computation.\n",
    "\t\tdevice ([type], optional): Device that compute is running on. Defaults to None.\n",
    "\n",
    "\tReturns:\n",
    "\t\tfloat: time between start and end in seconds (higher is longer).\n",
    "\t\"\"\"\n",
    "\ttotal_time = end - start\n",
    "\tprint(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "\treturn total_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825d9ea7",
   "metadata": {},
   "source": [
    "### 3.2) Function that calculates the accuracy between thruth labels and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722b3744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "\t\"\"\"Calculates accuracy between truth labels and predictions.\n",
    "\n",
    "\tArgs:\n",
    "\t\ty_true (torch.Tensor): Truth labels for predictions.\n",
    "\t\ty_pred (torch.Tensor): Predictions to be compared to predictions.\n",
    "\n",
    "\tReturns:\n",
    "\t\t[torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
    "\t\"\"\"\n",
    "\tcorrect = torch.eq(y_true, y_pred).sum().item()\n",
    "\tacc = (correct / len(y_pred)) * 100\n",
    "\treturn acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59281e4",
   "metadata": {},
   "source": [
    "### 3.3) Function that evaluates a model on a given Dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9aa204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(\n",
    "\tmodel: torch.nn.Module,\n",
    "\tdata_loader: torch.utils.data.DataLoader,\n",
    "\tloss_fn: torch.nn.Module,\n",
    "\taccuracy_fn,\n",
    "\tdevice: torch.device = device\n",
    "):\n",
    "\t\"\"\"\n",
    "\tEvaluates a model on a given DataLoader and computes loss, accuracy, and weighted ROC-AUC.\n",
    "\n",
    "\tArgs:\n",
    "\t\tmodel (torch.nn.Module):\n",
    "\t\t\tA PyTorch model to be evaluated.\n",
    "\t\tdata_loader (torch.utils.data.DataLoader):\n",
    "\t\t\tDataLoader containing the evaluation dataset.\n",
    "\t\tloss_fn (torch.nn.Module):\n",
    "\t\t\tLoss function used to compute model error.\n",
    "\t\taccuracy_fn (callable):\n",
    "\t\t\tFunction to compute accuracy between predictions and true labels.\n",
    "\t\tdevice (torch.device, optional):\n",
    "\t\t\tDevice on which to perform the evaluation (CPU or GPU).\n",
    "\t\t\tDefaults to the global `device`.\n",
    "\n",
    "\tReturns:\n",
    "\t\tdict:\n",
    "\t\t\tA dictionary containing the following metrics:\n",
    "\t\t\t- \"model_name\": Name of the evaluated model class.\n",
    "\t\t\t- \"model_loss\": Average loss computed over the data_loader.\n",
    "\t\t\t- \"model_acc\": Average accuracy.\n",
    "\t\t\t- \"roc_auc_weighted\": Weighted ROC-AUC score, useful for imbalanced datasets.\n",
    "\t\"\"\"\n",
    "\tloss, acc = 0.0, 0.0\n",
    "\ttrue_labels, all_probs = [], []\n",
    "\n",
    "\t# Move model once\n",
    "\tmodel.to(device)\n",
    "\tmodel.eval()\n",
    "\n",
    "\twith torch.inference_mode():\n",
    "\t\tfor X, y in data_loader:\n",
    "\t\t\t# Send batch to device\n",
    "\t\t\tX = X.to(device, non_blocking=True)\n",
    "\t\t\ty = y.to(device, non_blocking=True)\n",
    "\n",
    "\t\t\t# 1) Forward pass\n",
    "\t\t\ty_pred = model(X)\n",
    "\n",
    "\t\t\t# 2) Base metrics\n",
    "\t\t\tloss += float(loss_fn(y_pred, y).item())\n",
    "\t\t\tacc  += float(accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1)))\n",
    "\n",
    "\t\t\t# 3) Collect probabilities for ROC-AUC calculation (stored on CPU)\n",
    "\t\t\tif y_pred.ndim == 2 and y_pred.shape[1] > 1:\n",
    "\t\t\t\t# Multiclass (or binary with two logits)\n",
    "\t\t\t\tprobs = F.softmax(y_pred, dim=1).detach().cpu()\n",
    "\t\t\t\tall_probs.append(probs)\n",
    "\t\t\telse:\n",
    "\t\t\t\t# Binary with single logit\n",
    "\t\t\t\tpos_scores = torch.sigmoid(y_pred).detach().cpu().squeeze(1)\n",
    "\t\t\t\tall_probs.append(pos_scores)\n",
    "\n",
    "\t\t\ttrue_labels.append(y.detach().cpu())\n",
    "\n",
    "\t# Compute average across batches\n",
    "\tloss /= len(data_loader)\n",
    "\tacc /= len(data_loader)\n",
    "\n",
    "\t# Prepare for sklearn\n",
    "\ty_true   = torch.cat(true_labels).numpy()\n",
    "\tprob_blob = torch.cat(all_probs)\n",
    "\n",
    "\t# Weighted ROC-AUC\n",
    "\ttry:\n",
    "\t\tif prob_blob.ndim == 2 and prob_blob.shape[1] > 1:\n",
    "\t\t\troc_auc_weighted = roc_auc_score(\n",
    "\t\t\t\ty_true,\n",
    "\t\t\t\tprob_blob.numpy(),\n",
    "\t\t\t\tmulti_class=\"ovr\",\n",
    "\t\t\t\taverage=\"weighted\"\n",
    "\t\t\t)\n",
    "\t\telse:\n",
    "\t\t\troc_auc_weighted = roc_auc_score(y_true, prob_blob.numpy())\n",
    "\texcept ValueError:\n",
    "\t\troc_auc_weighted = float(\"nan\")\n",
    "\n",
    "\tprint(\n",
    "\t\tf\"Test  loss: {loss:.5f} | Test accuracy: {acc:.2f}% | ROC-AUC (weighted): {roc_auc_weighted:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e787f0",
   "metadata": {},
   "source": [
    "### 3.4) Function that extracts prediction probabilities and corresponding true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16f5878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _append_probs_and_labels(\n",
    "\tlogits: torch.Tensor,\n",
    "\ty: torch.Tensor,\n",
    "\tprobs_list: list,\n",
    "\tlabels_list: list\n",
    "):\n",
    "\t\"\"\"\n",
    "\tExtracts prediction probabilities and corresponding true labels for ROC-AUC computation.\n",
    "\n",
    "\t- For multiclass outputs (logits with shape [N, C], C > 1), applies softmax to get\n",
    "\t  class probabilities.\n",
    "\t- For binary outputs (logit with shape [N] or [N, 1]), applies sigmoid to obtain\n",
    "\t  probability of the positive class.\n",
    "\t- Moves tensors to CPU to avoid unnecessary GPU memory usage.\n",
    "\n",
    "\tArgs:\n",
    "\t\tlogits (torch.Tensor):\n",
    "\t\t\tRaw model outputs before activation.\n",
    "\t\ty (torch.Tensor):\n",
    "\t\t\tTrue labels associated with the batch.\n",
    "\t\tprobs_list (list):\n",
    "\t\t\tList to store detached probability tensors (CPU).\n",
    "\t\tlabels_list (list):\n",
    "\t\t\tList to store detached ground truth labels (CPU).\n",
    "\n",
    "\tReturns:\n",
    "\t\tNone. Modifies probs_list and labels_list in-place.\n",
    "\t\"\"\"\n",
    "\twith torch.no_grad():\n",
    "\t\tif logits.ndim == 2 and logits.shape[1] > 1:\n",
    "\t\t\t# Multiclass case -> softmax over classes\n",
    "\t\t\tprobs = F.softmax(logits, dim=1).detach().cpu()\n",
    "\t\t\tprobs_list.append(probs)\n",
    "\t\telse:\n",
    "\t\t\t# Binary case -> sigmoid score for positive class\n",
    "\t\t\tpos_scores = torch.sigmoid(logits).detach().cpu().squeeze(1)\n",
    "\t\t\tprobs_list.append(pos_scores)\n",
    "\n",
    "\t\tlabels_list.append(y.detach().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c24209",
   "metadata": {},
   "source": [
    "### 3.5) Function that performs one training epoch over a Dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65568336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(\n",
    "\tmodel: torch.nn.Module,\n",
    "\tdata_loader: torch.utils.data.DataLoader,\n",
    "\tloss_fn: torch.nn.Module,\n",
    "\toptimizer: torch.optim.Optimizer,\n",
    "\taccuracy_fn,\n",
    "\tdevice: torch.device = device,\n",
    "):\n",
    "\t\"\"\"\n",
    "\tPerforms one training epoch over a DataLoader and computes average loss, accuracy,\n",
    "\tand weighted ROC-AUC (using CPU for the AUC calculation). Moves data/model to the\n",
    "\tselected device (CPU/GPU) and applies a standard forward/backward/step routine.\n",
    "\n",
    "\tArgs:\n",
    "\t\tmodel (torch.nn.Module):\n",
    "\t\t\tPyTorch model to be trained for one epoch.\n",
    "\t\tdata_loader (torch.utils.data.DataLoader):\n",
    "\t\t\tDataLoader providing (inputs, targets) training batches.\n",
    "\t\tloss_fn (torch.nn.Module):\n",
    "\t\t\tLoss function used to compute the optimization objective.\n",
    "\t\toptimizer (torch.optim.Optimizer):\n",
    "\t\t\tOptimizer responsible for updating model parameters.\n",
    "\t\taccuracy_fn (callable):\n",
    "\t\t\tFunction that computes accuracy from (y_true, y_pred_labels).\n",
    "\t\tdevice (torch.device, optional):\n",
    "\t\t\tDevice on which to run training (CPU or GPU). Defaults to global `device`.\n",
    "\n",
    "\tReturns:\n",
    "\t\ttuple[float, float, float]:\n",
    "\t\t\t- train_loss (float): Mean loss over the epoch.\n",
    "\t\t\t- train_acc (float): Mean accuracy over the epoch.\n",
    "\t\t\t- train_auc_weighted (float): Weighted ROC-AUC over the epoch (NaN if undefined).\n",
    "\t\"\"\"\n",
    "\ttrain_loss, train_acc = 0.0, 0.0\n",
    "\ttrue_labels, all_probs = [], []\n",
    "\n",
    "\t# Move model once\n",
    "\tmodel.to(device)\n",
    "\tmodel.train()\n",
    "\n",
    "\tfor batch, (X, y) in enumerate(data_loader):\n",
    "\t\t# Move inputs to device\n",
    "\t\tX, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "\n",
    "\t\t# 1) Forward pass\n",
    "\t\ty_pred = model(X)\n",
    "\n",
    "\t\t# 2) Compute loss + accuracy\n",
    "\t\tloss = loss_fn(y_pred, y)\n",
    "\t\ttrain_loss += float(loss.item())\n",
    "\t\ttrain_acc  += float(accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1)))\n",
    "\n",
    "\t\t# 3) Zero gradients\n",
    "\t\toptimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "\t\t# 4) Backward pass\n",
    "\t\tloss.backward()\n",
    "\n",
    "\t\t# 5) Optimizer update\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\t# 6) Accumulate predictions for AUC\n",
    "\t\t_append_probs_and_labels(y_pred, y, all_probs, true_labels)\n",
    "\n",
    "\t\t# Progress log\n",
    "\t\tif batch % 8 == 0:\n",
    "\t\t\tprint(f\"Looked at {batch * len(X)}/{len(data_loader.dataset)} samples\")\n",
    "\n",
    "\t# Epoch averaging\n",
    "\ttrain_loss /= len(data_loader)\n",
    "\ttrain_acc  /= len(data_loader)\n",
    "\n",
    "\t# ROC-AUC Weighted (CPU fallback)\n",
    "\ttry:\n",
    "\t\ty_true = torch.cat(true_labels).numpy()\n",
    "\t\tprob_blob = torch.cat(all_probs)\n",
    "\n",
    "\t\tif prob_blob.ndim == 2 and prob_blob.shape[1] > 1:\n",
    "\t\t\t# Multiclass weighted ROC-AUC\n",
    "\t\t\ttrain_auc_weighted = roc_auc_score(\n",
    "\t\t\t\ty_true,\n",
    "\t\t\t\tprob_blob.numpy(),\n",
    "\t\t\t\tmulti_class=\"ovr\",\n",
    "\t\t\t\taverage=\"weighted\"\n",
    "\t\t\t)\n",
    "\t\telse:\n",
    "\t\t\t# Binary ROC-AUC\n",
    "\t\t\ttrain_auc_weighted = roc_auc_score(y_true, prob_blob.numpy())\n",
    "\texcept ValueError:\n",
    "\t\ttrain_auc_weighted = float(\"nan\")\n",
    "\n",
    "\tprint(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}% | ROC-AUC (weighted): {train_auc_weighted:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef18e86a",
   "metadata": {},
   "source": [
    "### 3.6) Function that evaluates a model on a validation/test Dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb739bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(\n",
    "\tdata_loader: torch.utils.data.DataLoader,\n",
    "\tmodel: torch.nn.Module,\n",
    "\tloss_fn: torch.nn.Module,\n",
    "\taccuracy_fn,\n",
    "\tdevice: torch.device = device\n",
    "):\n",
    "\t\"\"\"\n",
    "\tEvaluates a model on a validation or test DataLoader and computes average loss,\n",
    "\taccuracy, and weighted ROC-AUC. Runs entirely in inference mode and moves\n",
    "\ttensors to the selected device (CPU/GPU) for efficiency.\n",
    "\n",
    "\tArgs:\n",
    "\t\tdata_loader (torch.utils.data.DataLoader):\n",
    "\t\t\tDataLoader providing validation/test batches.\n",
    "\t\tmodel (torch.nn.Module):\n",
    "\t\t\tModel to be evaluated.\n",
    "\t\tloss_fn (torch.nn.Module):\n",
    "\t\t\tLoss function used to evaluate prediction error.\n",
    "\t\taccuracy_fn (callable):\n",
    "\t\t\tFunction that computes accuracy from (y_true, y_pred_labels).\n",
    "\t\tdevice (torch.device, optional):\n",
    "\t\t\tDevice on which evaluation runs. Defaults to global `device`.\n",
    "\n",
    "\tReturns:\n",
    "\t\ttuple[float, float, float]:\n",
    "\t\t\t- test_loss (float): Mean loss over the evaluation DataLoader.\n",
    "\t\t\t- test_acc (float): Mean accuracy.\n",
    "\t\t\t- roc_auc_weighted (float): Weighted ROC-AUC score (NaN if undefined).\n",
    "\t\"\"\"\n",
    "\ttest_loss, test_acc = 0.0, 0.0\n",
    "\ttrue_labels, all_probs = [], []\n",
    "\n",
    "\t# Move model to device\n",
    "\tmodel.to(device)\n",
    "\tmodel.eval()\n",
    "\n",
    "\twith torch.inference_mode():\n",
    "\t\tfor X, y in data_loader:\n",
    "\t\t\t# Move batch to device\n",
    "\t\t\tX, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "\n",
    "\t\t\t# 1) Forward pass\n",
    "\t\t\ttest_pred = model(X)\n",
    "\n",
    "\t\t\t# 2) Compute base metrics\n",
    "\t\t\ttest_loss += float(loss_fn(test_pred, y).item())\n",
    "\t\t\ttest_acc  += float(accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1)))\n",
    "\n",
    "\t\t\t# 3) Accumulate probabilities and labels for ROC-AUC (stored on CPU)\n",
    "\t\t\t_append_probs_and_labels(test_pred, y, all_probs, true_labels)\n",
    "\n",
    "\t# Average across batches\n",
    "\ttest_loss /= len(data_loader)\n",
    "\ttest_acc  /= len(data_loader)\n",
    "\n",
    "\t# ROC-AUC Weighted (CPU-based computation)\n",
    "\ttry:\n",
    "\t\ty_true = torch.cat(true_labels).numpy()\n",
    "\t\tprob_blob = torch.cat(all_probs)\n",
    "\n",
    "\t\tif prob_blob.ndim == 2 and prob_blob.shape[1] > 1:\n",
    "\t\t\troc_auc_weighted = roc_auc_score(\n",
    "\t\t\t\ty_true,\n",
    "\t\t\t\tprob_blob.numpy(),\n",
    "\t\t\t\tmulti_class=\"ovr\",\n",
    "\t\t\t\taverage=\"weighted\"\n",
    "\t\t\t)\n",
    "\t\telse:\n",
    "\t\t\troc_auc_weighted = roc_auc_score(y_true, prob_blob.numpy())\n",
    "\texcept ValueError:\n",
    "\t\troc_auc_weighted = float(\"nan\")\n",
    "\n",
    "\tprint(f\"Test  loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}% | ROC-AUC (weighted): {roc_auc_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46b5d44",
   "metadata": {},
   "source": [
    "### 3.7) Function that computes per-channel mean and standar deviation from a training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2e3677",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_mean_std_from_path(\n",
    "\ttrain_dir,\n",
    "\timg_size=(227, 227),\n",
    "\tbatch_size=64,\n",
    "\tnum_workers=4,\n",
    "\tuse_gpu=True\n",
    "):\n",
    "\t\"\"\"\n",
    "\tComputes per-channel mean and standard deviation from a training dataset located at train_dir.\n",
    "\tA temporary ImageFolder is created using a minimal transform (Resize -> ToTensor) without\n",
    "\tany normalization or augmentation to ensure raw pixel distribution is measured correctly.\n",
    "\n",
    "\tArgs:\n",
    "\t\ttrain_dir (str or Path):\n",
    "\t\t\tPath to the training image directory (must be compatible with ImageFolder structure).\n",
    "\t\timg_size (tuple[int, int], optional):\n",
    "\t\t\tImage size to which all images will be resized before computing statistics.\n",
    "\t\t\tDefaults to (227, 227), matching your current training pipeline.\n",
    "\t\tbatch_size (int, optional):\n",
    "\t\t\tBatch size used when loading images to calculate statistics.\n",
    "\t\tnum_workers (int, optional):\n",
    "\t\t\tNumber of subprocesses to use for data loading (CPU threads).\n",
    "\t\tuse_gpu (bool, optional):\n",
    "\t\t\tIf True and a CUDA GPU is available, accumulation is performed on GPU memory\n",
    "\t\t\tfor faster computation. Final values are moved back to CPU.\n",
    "\n",
    "\tReturns:\n",
    "\t\ttuple[list[float], list[float]]:\n",
    "\t\t\t- mean: List of channel-wise means (e.g., [0.612, 0.448, 0.391])\n",
    "\t\t\t- std:  List of channel-wise standard deviations\n",
    "\t\"\"\"\n",
    "\t# Temporary dataset for statistics only (no Normalize, no augmentations)\n",
    "\tstats_tf = transforms.Compose([\n",
    "\t\ttransforms.Resize(img_size),\n",
    "\t\ttransforms.ToTensor()\n",
    "\t])\n",
    "\ttmp_ds = datasets.ImageFolder(root=train_dir, transform=stats_tf)\n",
    "\n",
    "\tdevice = torch.device(\"cuda\" if (use_gpu and torch.cuda.is_available()) else \"cpu\")\n",
    "\tloader = DataLoader(\n",
    "\t\ttmp_ds,\n",
    "\t\tbatch_size=batch_size,\n",
    "\t\tshuffle=False,\n",
    "\t\tnum_workers=num_workers if torch.cuda.is_available() else 0,\n",
    "\t\tpin_memory=torch.cuda.is_available()\n",
    "\t)\n",
    "\n",
    "\tsum_c = None\n",
    "\tsum2_c = None\n",
    "\tn_pix_total = 0\n",
    "\n",
    "\tfor imgs, *_ in loader:\n",
    "\t\t# imgs: [N, C, H, W] in [0, 1]\n",
    "\t\tif device.type == \"cuda\":\n",
    "\t\t\timgs = imgs.to(device, non_blocking=True)\n",
    "\n",
    "\t\tN, C, H, W = imgs.shape\n",
    "\t\tpix = N * H * W\n",
    "\n",
    "\t\tif sum_c is None:\n",
    "\t\t\tsum_c = torch.zeros(C, device=device, dtype=torch.float64)\n",
    "\t\t\tsum2_c = torch.zeros(C, device=device, dtype=torch.float64)\n",
    "\n",
    "\t\tsum_c += imgs.sum(dim=(0, 2, 3), dtype=torch.float64)\n",
    "\t\tsum2_c += (imgs * imgs).sum(dim=(0, 2, 3), dtype=torch.float64)\n",
    "\t\tn_pix_total += pix\n",
    "\n",
    "\t# Finalize mean/std and return CPU float lists\n",
    "\tmean = (sum_c / n_pix_total).to(\"cpu\").float()\n",
    "\tvar  = (sum2_c / n_pix_total) - (sum_c / n_pix_total) ** 2\n",
    "\tvar  = torch.clamp(var, min=0.0)  # Avoid small negative values due to precision\n",
    "\tstd  = torch.sqrt(var).to(\"cpu\").float()\n",
    "\n",
    "\treturn mean.tolist(), std.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ffefce",
   "metadata": {},
   "source": [
    "### 3.8) Function that plots a set of randomly selected images before and after applying a given transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97897813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transformed_images(image_paths, transform, n=3, seed=42):\n",
    "\t\"\"\"\n",
    "\tPlots a set of randomly selected images before and after applying a given transform.\n",
    "\n",
    "\tArgs:\n",
    "\t\timage_paths (list[pathlib.Path] or list[str]):\n",
    "\t\t\tList of file paths to images that will be sampled and visualized.\n",
    "\t\ttransform (callable or torchvision.transforms):\n",
    "\t\t\tTransform to be applied to each image (must return a tensor in [C, H, W] format).\n",
    "\t\tn (int, optional):\n",
    "\t\t\tNumber of images to randomly sample and visualize. Defaults to 3.\n",
    "\t\tseed (int, optional):\n",
    "\t\t\tRandom seed to ensure reproducible sampling. Defaults to 42.\n",
    "\n",
    "\tReturns:\n",
    "\t\tNone. Displays Matplotlib figures showing original vs transformed images.\n",
    "\t\"\"\"\n",
    "\trandom.seed(seed)\n",
    "\trandom_image_paths = random.sample(image_paths, k=n)\n",
    "\n",
    "\tfor image_path in random_image_paths:\n",
    "\t\twith Image.open(image_path) as f:\n",
    "\t\t\tfig, ax = plt.subplots(1, 2)\n",
    "\n",
    "\t\t\t# Original image\n",
    "\t\t\tax[0].imshow(f)\n",
    "\t\t\tax[0].set_title(f\"Original \\nSize: {f.size}\")\n",
    "\t\t\tax[0].axis(\"off\")\n",
    "\n",
    "\t\t\t# Apply transform and permute for matplotlib compatibility\n",
    "\t\t\ttransformed_image = transform(f).permute(1, 2, 0)\n",
    "\t\t\tax[1].imshow(transformed_image)\n",
    "\t\t\tax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n",
    "\t\t\tax[1].axis(\"off\")\n",
    "\n",
    "\t\t\tfig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cdfc84",
   "metadata": {},
   "source": [
    "### 3.9) Function that normalizes a label string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5fab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_label(s: str) -> str:\n",
    "\t\"\"\"\n",
    "\tNormalizes a label string by converting to lowercase, replacing spaces/hyphens\n",
    "\twith underscores, and stripping unsupported characters.\n",
    "\n",
    "\tArgs:\n",
    "\t\ts (str): Raw label string.\n",
    "\n",
    "\tReturns:\n",
    "\t\tstr: Clean normalized label string.\n",
    "\t\"\"\"\n",
    "\treturn re.sub(r\"[^a-z0-9_]+\", \"\", s.strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7599d3e3",
   "metadata": {},
   "source": [
    "### 3.10) Function that extracts the base filename from a file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0037a637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_id_from_path(path: str) -> str:\n",
    "\t\"\"\"\n",
    "\tExtracts the base filename (without extension) from a file path.\n",
    "\n",
    "\tExample:\n",
    "\t\t/a/b/ISIC_0001.jpg -> \"ISIC_0001\"\n",
    "\n",
    "\tArgs:\n",
    "\t\tpath (str): File path to extract the ID from.\n",
    "\n",
    "\tReturns:\n",
    "\t\tstr: File identifier without extension.\n",
    "\t\"\"\"\n",
    "\treturn os.path.splitext(os.path.basename(path))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f830dbe",
   "metadata": {},
   "source": [
    "### 3.11) Function that maps model output class indices to a fixed desired order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c411a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prob_reorder_indices(dataset, n_classes):\n",
    "\t\"\"\"\n",
    "\tMaps model output class indices to a fixed desired order defined in _TARGET_LABELS.\n",
    "\tIf the dataset exposes class_to_idx, this function attempts to align the output\n",
    "\tprobabilities with the expected label order (useful for generating CSV submissions).\n",
    "\n",
    "\tArgs:\n",
    "\t\tdataset: Dataset object with optional class_to_idx mapping.\n",
    "\t\tn_classes (int): Number of output classes from the model.\n",
    "\n",
    "\tReturns:\n",
    "\t\tlist[int]: Index mapping to reorder probability outputs. Identity map if matching fails.\n",
    "\t\"\"\"\n",
    "\tidx_map = list(range(n_classes))  # default identity map\n",
    "\t\n",
    "\tclass_to_idx = getattr(dataset, \"class_to_idx\", None)\n",
    "\tif isinstance(class_to_idx, dict) and len(class_to_idx) == n_classes:\n",
    "\t\tidx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\t\tderived = []\n",
    "\t\tfor lab in _TARGET_LABELS:\n",
    "\t\t\tlab_clean = _clean_label(lab)\n",
    "\t\t\tfound_idx = None\n",
    "\t\t\tfor i in range(n_classes):\n",
    "\t\t\t\tds_lab = _clean_label(str(idx_to_class.get(i, \"\")))\n",
    "\t\t\t\tif ds_lab == lab_clean:\n",
    "\t\t\t\t\tfound_idx = i\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\tif found_idx is None:\n",
    "\t\t\t\t# Fallback to identity if any target label is not matched\n",
    "\t\t\t\treturn idx_map\n",
    "\t\t\tderived.append(found_idx)\n",
    "\t\treturn derived\n",
    "\n",
    "\treturn idx_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0065064",
   "metadata": {},
   "source": [
    "### 3.12) Function that attempts to infer image identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c3616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _infer_id_sequence(test_loader):\n",
    "\t\"\"\"\n",
    "\tAttempts to infer image identifiers by inspecting dataset attributes such as\n",
    "\t`samples`, `imgs`, or custom path lists. This works well when shuffle=False.\n",
    "\n",
    "\tArgs:\n",
    "\t\ttest_loader (torch.utils.data.DataLoader): Loader for test/inference dataset.\n",
    "\n",
    "\tReturns:\n",
    "\t\tlist[str] or None: Ordered list of image IDs if paths are accessible, else None.\n",
    "\t\"\"\"\n",
    "\tds = getattr(test_loader, \"dataset\", None)\n",
    "\tfor attr in (\"samples\", \"imgs\"):  # list of (path, label)\n",
    "\t\tif hasattr(ds, attr):\n",
    "\t\t\tpairs = getattr(ds, attr)\n",
    "\t\t\treturn [_extract_id_from_path(p) for p, _ in pairs]\n",
    "\tfor attr in (\"image_paths\", \"images\", \"files\", \"paths\"):\n",
    "\t\tif hasattr(ds, attr):\n",
    "\t\t\tpaths = getattr(ds, attr)\n",
    "\t\t\tif isinstance(paths, (list, tuple)) and isinstance(paths[0], str):\n",
    "\t\t\t\treturn [_extract_id_from_path(p) for p in paths]\n",
    "\treturn None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56c9bc0",
   "metadata": {},
   "source": [
    "## 4) Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797c1ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directory\n",
    "image_path = Path(\"skin-lesions/\")\n",
    "print(f\"Image path exists: {image_path.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82867c4",
   "metadata": {},
   "source": [
    "### 4.1) Function that walks recursively through a directory and prints a summary of its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9515e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_through_dir(dir_path):\n",
    "\t\"\"\"\n",
    "\tWalks recursively through a directory and prints a summary of its contents.\n",
    "\n",
    "\tArgs:\n",
    "\t\tdir_path (str or pathlib.Path):\n",
    "\t\t\tTarget directory to inspect.\n",
    "\n",
    "\tReturns:\n",
    "\t\tNone. Prints:\n",
    "\t\t\t- Number of subdirectories inside each folder.\n",
    "\t\t\t- Number of files (images) found in each folder.\n",
    "\t\t\t- Full path of each folder visited.\n",
    "\t\"\"\"\n",
    "\tfor dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "\t\tprint(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dd95c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheking the content of our image path\n",
    "walk_through_dir(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a2a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train, test and validation directories\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "val_dir = image_path / \"valid\"\n",
    "\n",
    "train_dir, test_dir, val_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5445feae",
   "metadata": {},
   "source": [
    "## 5) Visualizing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd6e45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all image paths\n",
    "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
    "\n",
    "# Select a random image path\n",
    "random_image_path = random.choice(image_path_list)\n",
    "\n",
    "# Get the class name from the image path\n",
    "class_name = random_image_path.parent.name\n",
    "\n",
    "# Open the image\n",
    "img = Image.open(random_image_path)\n",
    "\n",
    "# Print out some information about the image\n",
    "print(f\"Image path: {random_image_path}\")\n",
    "print(f\"Class name: {class_name}\")\n",
    "print(f\"Image size: {img.size}\")\n",
    "print(f\"Image format: {img.format}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca84f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the image\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb76af23",
   "metadata": {},
   "source": [
    "## 6) Transforming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1f23db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the mean and std of our training dataset\n",
    "if PRETRAINED_RESTNET18:\n",
    "\tDATASET_MEAN = [0.485, 0.456, 0.406]\n",
    "\tDATASET_STD = [0.229, 0.224, 0.225]\n",
    "else:\n",
    "\tDATASET_MEAN, DATASET_STD = compute_mean_std_from_path(\n",
    "\t\ttrain_dir,\n",
    "\t\timg_size=(227, 227),\n",
    "\t\tbatch_size=64,\n",
    "\t\tnum_workers=4,\n",
    "\t\tuse_gpu=True\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc74cd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out the mean and std\n",
    "print(\"mean (training dataset):\", DATASET_MEAN)\n",
    "print(\"std (training dataset):\", DATASET_STD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4759bc85",
   "metadata": {},
   "source": [
    "### 6.1) Defining data transformers for training and evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2891a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data transformer\n",
    "train_data_transform = transforms.Compose([\n",
    "\ttransforms.Resize(size=(227, 227)),\n",
    "\ttransforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "\ttransforms.ToTensor(),\n",
    "\ttransforms.Normalize(mean=DATASET_MEAN, std=DATASET_STD)\n",
    "])\n",
    "\n",
    "# Training data transformer\n",
    "eval_data_transform = transforms.Compose([\n",
    "\ttransforms.Resize(size=(227, 227)),\n",
    "\ttransforms.ToTensor(),\n",
    "\ttransforms.Normalize(mean=DATASET_MEAN, std=DATASET_STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cae3573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting random images to show the images before and after appliying the transformer\n",
    "plot_transformed_images(image_path_list, train_data_transform, n=3, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7613c567",
   "metadata": {},
   "source": [
    "## 7) Loading our images into datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70fd93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, test and validation datasets\n",
    "train_data = datasets.ImageFolder(\n",
    "\troot=train_dir,\n",
    "\ttransform=train_data_transform\n",
    ")\n",
    "\n",
    "test_data = datasets.ImageFolder(\n",
    "\troot=test_dir,\n",
    "\ttransform=eval_data_transform\n",
    ")\n",
    "\n",
    "val_data = datasets.ImageFolder(\n",
    "\troot=val_dir,\n",
    "\ttransform=eval_data_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eb08e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out some information about the datasets\n",
    "print(f\"- Train data: {train_data}\\n\\n- Test data: {test_data}\\n\\n- Validation data: {val_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8ec116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out some information about the datasets\n",
    "print(f\"Number of classes: {len(train_data.classes)}\")\n",
    "print(f\"Class names: {train_data.classes}\")\n",
    "print(f\"Class dictionary: {train_data.class_to_idx}\")\n",
    "print(f\"Number of training images: {len(train_data)}\")\n",
    "print(f\"Number of test images: {len(test_data)}\")\n",
    "print(f\"Number of validation images: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d51328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out some information about an image in our training dataset\n",
    "img, label = train_data[0][0], train_data[0][1]\n",
    "print(f\"Image shape: {img.shape} | Image datatype: {img.dtype} | Label: {label} | Label datatype: {type(label)}\")\n",
    "print(f\"Image Tensor:\\n{img}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716c9b3c",
   "metadata": {},
   "source": [
    "## 8) View an Image from our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57452002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change image shape for plotting\n",
    "img_prmt = img.permute(1, 2, 0)\n",
    "\n",
    "# Print out image shape and datatype\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Permuted image shape: {img_prmt.shape}\")\n",
    "\n",
    "# Plot the image\n",
    "plt.imshow(img_prmt)\n",
    "plt.title(f\"Label: {label}, Class name: {train_data.classes[label]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c18f170",
   "metadata": {},
   "source": [
    "## 9) Loading our data into DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f97058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Sampler to handle unbalanced classes\n",
    "targets = np.array(train_data.targets)\n",
    "class_sample_count = np.bincount(targets)\n",
    "weights = 1.0 / class_sample_count\n",
    "sample_weights = weights[targets]\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# Create DataLoaders for training, testing, and validation datasets\n",
    "train_loader = DataLoader(\n",
    "\ttrain_data,\n",
    "\tbatch_size=64,\n",
    "\tnum_workers=4 if torch.cuda.is_available() else 0,\n",
    "\tpin_memory=torch.cuda.is_available(), \n",
    "\tprefetch_factor=2 if torch.cuda.is_available() else None, \n",
    "\tsampler=sampler,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "\ttest_data,\n",
    "\tbatch_size=64,\n",
    "\tnum_workers=4 if torch.cuda.is_available() else 0,\n",
    "\tpin_memory=torch.cuda.is_available(),  \n",
    "\tprefetch_factor=2 if torch.cuda.is_available() else None, \n",
    "\tshuffle=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "\tval_data,\n",
    "\tbatch_size=64,\n",
    "\tnum_workers=4 if torch.cuda.is_available() else 0,\n",
    "\tpin_memory=torch.cuda.is_available(),  \n",
    "\tprefetch_factor=2 if torch.cuda.is_available() else None, \n",
    "\tshuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840c4c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of data\n",
    "train_features_batch, train_labels_batch = next(iter(train_loader))\n",
    "\n",
    "# Print out some information about the batch\n",
    "print(f\"Features batch shape: {train_features_batch.shape} | Features datatype: {train_features_batch.dtype}\")\n",
    "print(f\"Label batch shape: {train_labels_batch.shape} | Label datatype: {train_labels_batch.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747f2c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random image from the batch\n",
    "idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
    "img, label = train_features_batch[idx], train_labels_batch[idx]\n",
    "\n",
    "# Change image shape for plotting\n",
    "img_prmt = img.permute(1, 2, 0)\n",
    "\n",
    "# Plot a random image from the batch\n",
    "plt.imshow(img_prmt)\n",
    "plt.title(f\"Label: {label}, Class name: {train_data.classes[label]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1981acb",
   "metadata": {},
   "source": [
    "## 10) Defining our CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce2bf41",
   "metadata": {},
   "source": [
    "### 10.1) Trying out the AlexNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76895e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model using the AlexNet architecture\n",
    "class AlexNet(nn.Module):\n",
    "\tdef __init__(self, input_channels: int, num_classes: int):\n",
    "\t\tsuper().__init__()\n",
    "\t\t# Bloques convolucionales con BatchNorm; AdaptiveAvgPool2d(6,6) para tamaño robusto\n",
    "\t\tself.features = nn.Sequential(\n",
    "\t\t\t# Conv1\n",
    "\t\t\tnn.Conv2d(input_channels, 96, kernel_size=11, stride=4, padding=2),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.BatchNorm2d(96),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "\t\t\t# Conv2\n",
    "\t\t\tnn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.BatchNorm2d(256),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "\t\t\t# Conv3\n",
    "\t\t\tnn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.BatchNorm2d(384),\n",
    "\n",
    "\t\t\t# Conv4\n",
    "\t\t\tnn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.BatchNorm2d(384),\n",
    "\n",
    "\t\t\t# Conv5\n",
    "\t\t\tnn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.BatchNorm2d(256),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "\t\t\t# Asegura 6x6 sin depender del tamaño de entrada exacto\n",
    "\t\t\tnn.AdaptiveAvgPool2d((6, 6))\n",
    "\t\t)\n",
    "\n",
    "\t\tself.classifier = nn.Sequential(\n",
    "\t\t\tnn.Flatten(),\n",
    "\t\t\tnn.Dropout(p=0.5),\n",
    "\t\t\tnn.Linear(256 * 6 * 6, 4096),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.Dropout(p=0.5),\n",
    "\t\t\tnn.Linear(4096, 4096),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.Linear(4096, num_classes)\n",
    "\t\t)\n",
    "\n",
    "\t\tself._init_weights()\n",
    "\n",
    "\tdef _init_weights(self):\n",
    "\t\t# Inicialización Kaiming adecuada para ReLU\n",
    "\t\tfor m in self.modules():\n",
    "\t\t\tif isinstance(m, nn.Conv2d):\n",
    "\t\t\t\tnn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "\t\t\t\tif m.bias is not None:\n",
    "\t\t\t\t\tnn.init.zeros_(m.bias)\n",
    "\t\t\telif isinstance(m, nn.Linear):\n",
    "\t\t\t\tnn.init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
    "\t\t\t\tif m.bias is not None:\n",
    "\t\t\t\t\tnn.init.zeros_(m.bias)\n",
    "\t\t\telif isinstance(m, nn.BatchNorm2d):\n",
    "\t\t\t\tnn.init.ones_(m.weight)\n",
    "\t\t\t\tnn.init.zeros_(m.bias)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.features(x)\n",
    "\t\tx = self.classifier(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e1194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our AlexNet model\n",
    "alexnet_model = AlexNet(\n",
    "\tinput_channels=3,\n",
    "\tnum_classes=len(train_data.classes),\n",
    ")\n",
    "\n",
    "# Send to device\n",
    "model = alexnet_model.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f961bcc",
   "metadata": {},
   "source": [
    "### 10.2a) Trying out the ResNet-18 architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db38a671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our ResNet-18 model\n",
    "resnet18_model = models.resnet18(\n",
    "\tweights=None,\n",
    "\tnum_classes=len(train_data.classes)\n",
    ")\n",
    "\n",
    "# Replace final classification layer\n",
    "resnet18_model.fc = nn.Linear(\n",
    "\tresnet18_model.fc.in_features,\n",
    "\tlen(train_data.classes)\n",
    ")\n",
    "\n",
    "# Send to device\n",
    "model = resnet18_model.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db6ec65",
   "metadata": {},
   "source": [
    "### 10.2b) Trying out the pretrained ResNet-18 architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb77664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our pretrained ResNet-18 model\n",
    "pretrained_resnet18_model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Replace final classification layer\n",
    "pretrained_resnet18_model.fc = nn.Linear(\n",
    "\tpretrained_resnet18_model.fc.in_features,\n",
    "\tlen(train_data.classes)\n",
    ")\n",
    "\n",
    "# Send to device\n",
    "model = pretrained_resnet18_model.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1ff151",
   "metadata": {},
   "source": [
    "### 10.3) Calculating class weights to manage unbalanced classes and setting up our loss and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d97246",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "\tdef __init__(self, alpha=None, gamma=2.0, reduction=\"mean\"):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.alpha = alpha  # tensor of class weights or None\n",
    "\t\tself.gamma = gamma\n",
    "\t\tself.reduction = reduction\n",
    "\n",
    "\tdef forward(self, logits, targets):\n",
    "\t\tce = F.cross_entropy(logits, targets, weight=self.alpha, reduction=\"none\")\n",
    "\t\tpt = torch.softmax(logits, dim=1).gather(1, targets.unsqueeze(1)).squeeze(1).clamp_min(1e-8)\n",
    "\t\tfocal = (1 - pt) ** self.gamma * ce\n",
    "\t\tif self.reduction == \"mean\":\n",
    "\t\t\treturn focal.mean()\n",
    "\t\telif self.reduction == \"sum\":\n",
    "\t\t\treturn focal.sum()\n",
    "\t\treturn focal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e576997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(train_data.targets), y=train_data.targets)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device=device)\n",
    "\n",
    "# Setup loss\n",
    "# loss_fn = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.05)\n",
    "loss_fn = FocalLoss(alpha=class_weights, gamma=1.5) \n",
    "\n",
    "# Setup optimizer\n",
    "if PRETRAINED_RESTNET18:\n",
    "\t# Only optimize parameters that require grad\n",
    "\ttrainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "\toptimizer = torch.optim.SGD(params=trainable_params, lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "else:\n",
    "\toptimizer = torch.optim.SGD(params=model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f06c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up our scheduler\n",
    "steps_per_epoch = len(train_loader)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "\toptimizer=optimizer,\n",
    "\tmax_lr=0.03,\n",
    "\tsteps_per_epoch=steps_per_epoch,\n",
    "\tepochs=NUM_EPOCHS,\n",
    "\tpct_start=0.1,\n",
    "\tanneal_strategy=\"cos\",\n",
    "\tdiv_factor=10.0,\n",
    "\tfinal_div_factor=100.0\t\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba85625",
   "metadata": {},
   "source": [
    "### 10.4) Training and evaluating our model using the training and evaluating DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8332a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time_start_on_gpu = timer()\n",
    "\n",
    "epochs = NUM_EPOCHS\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\tprint(f\"Epoch: {epoch}\\n---------\")\n",
    "\ttrain_step(\n",
    "\t\tdata_loader=train_loader,\n",
    "\t\tmodel=model,\n",
    "\t\tloss_fn=loss_fn,\n",
    "\t\toptimizer=optimizer,\n",
    "\t\taccuracy_fn=accuracy_fn)\n",
    "\ttest_step(\n",
    "\t\tdata_loader=val_loader,\n",
    "\t\tmodel=model,\n",
    "\t\tloss_fn=loss_fn,\n",
    "\t\taccuracy_fn=accuracy_fn)\n",
    "\tscheduler.step()\n",
    "\n",
    "train_time_end_on_gpu = timer()\n",
    "total_train_time_model_1 = print_train_time(\n",
    "\tstart=train_time_start_on_gpu,\n",
    "\tend=train_time_end_on_gpu,\n",
    "\tdevice=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc2116d",
   "metadata": {},
   "source": [
    "### 10.5) Evaluate our model using the testing DataLoader and create the Kaggle CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7a60c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(\n",
    "\tmodel=model,\n",
    "\tdata_loader=test_loader,\n",
    "\tloss_fn=loss_fn,\n",
    "\taccuracy_fn=accuracy_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffc096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Inference & CSV export loop ----------\n",
    "model.eval()\n",
    "all_rows = []\n",
    "n_classes = None\n",
    "\n",
    "# Attempt to infer global ID order for consistent o]utput\n",
    "global_ids = _infer_id_sequence(test_loader)\n",
    "global_cursor = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "\tfor batch in test_loader:\n",
    "\t\t# Automatically detect whether batch contains images only or also IDs/labels\n",
    "\t\tif isinstance(batch, (list, tuple)):\n",
    "\t\t\tif len(batch) == 3:\n",
    "\t\t\t\tX, y_or_ids, ids_or_none = batch\n",
    "\t\t\t\tif torch.is_tensor(y_or_ids):\n",
    "\t\t\t\t\tX, ids = X, ids_or_none  # (images, labels, ids)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tX, ids = X, y_or_ids      # (images, ids, _)\n",
    "\t\t\telif len(batch) == 2:\n",
    "\t\t\t\ta, b = batch\n",
    "\t\t\t\tif torch.is_tensor(b) and torch.is_tensor(a):\n",
    "\t\t\t\t\tX, ids = a, None           # (images, labels)\n",
    "\t\t\t\telif torch.is_tensor(a):\n",
    "\t\t\t\t\tX, ids = a, b              # (images, ids)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tX, ids = a, b\n",
    "\t\t\telse:\n",
    "\t\t\t\tX, ids = batch, None\n",
    "\t\telse:\n",
    "\t\t\tX, ids = batch, None\n",
    "\n",
    "\t\t# Forward pass on device\n",
    "\t\tX = X.to(device)\n",
    "\t\tlogits = model(X)\n",
    "\n",
    "\t\t# Get number of classes once\n",
    "\t\tif n_classes is None:\n",
    "\t\t\tn_classes = logits.shape[-1]\n",
    "\n",
    "\t\t# Convert logits to probabilities\n",
    "\t\tprobs = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "\t\t# Resolve IDs\n",
    "\t\tif ids is not None:\n",
    "\t\t\ttry:\n",
    "\t\t\t\tbatch_ids = [os.path.splitext(os.path.basename(str(i)))[0] for i in ids]\n",
    "\t\t\texcept Exception:\n",
    "\t\t\t\tbatch_ids = [str(i) for i in ids]\n",
    "\t\telif global_ids is not None:\n",
    "\t\t\tbsz = probs.shape[0]\n",
    "\t\t\tbatch_ids = global_ids[global_cursor:global_cursor + bsz]\n",
    "\t\t\tglobal_cursor += bsz\n",
    "\t\telse:\n",
    "\t\t\tbatch_ids = [f\"val_{len(all_rows) + i:06d}\" for i in range(probs.shape[0])]\n",
    "\n",
    "\t\t# Map output indices if class order differs from target submission format\n",
    "\t\tidx_map = _prob_reorder_indices(getattr(test_loader, \"dataset\", None), probs.shape[1])\n",
    "\n",
    "\t\tfor img_id, p in zip(batch_ids, probs):\n",
    "\t\t\tp_ordered = [float(p[idx_map[i]]) for i in range(len(_TARGET_LABELS))]\n",
    "\t\t\tall_rows.append({\n",
    "\t\t\t\t\"Id\": img_id,\n",
    "\t\t\t\t\"melanoma\": p_ordered[0],\n",
    "\t\t\t\t\"nevus\": p_ordered[1],\n",
    "\t\t\t\t\"seborrheic_keratosis\": p_ordered[2],\n",
    "\t\t\t})\n",
    "\n",
    "# ---------- Create CSV ----------\n",
    "df_sub = pd.DataFrame(all_rows, columns=[\"Id\"] + _TARGET_LABELS)\n",
    "df_sub[\"Id\"] = df_sub[\"Id\"].astype(str) + \".jpg\"\n",
    "df_sub.to_csv(f\"submission_{MODEL_NAME}.csv\", index=False)\n",
    "\n",
    "print(f\"✅ CSV generated: submission.csv | Total rows: {len(df_sub)}\")\n",
    "df_sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
